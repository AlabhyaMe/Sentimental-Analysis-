{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the packages\n",
    "import polars as pl\n",
    "#make sure that this is the main file\n",
    "import sys\n",
    "import os\n",
    "project_root = os.getcwd()\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your data as Train.csv and place it in the Training Data folder. Or you can change the path in the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 162758 rows and 5 columns\n"
     ]
    }
   ],
   "source": [
    "# keep you training dataset in the training data folder\n",
    "# this template uses csv files \n",
    "# column names can be set in Python but this template does not automatically update the column for the demo \n",
    "# however, the function will give you the option to tell column names for the text and label data\n",
    "\n",
    "df_train = pl.read_csv(\"Training Data/Train.csv\",encoding='ISO-8859-1') \n",
    "print(f\"Dataset shape: {df_train.shape[0]} rows and {df_train.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (16_275, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isFrequentReviewer</th><th>reviewText</th><th>sentiment</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;john_mcclane_rocky_balboa_laby…</td><td>&quot;Deborah Farley&quot;</td><td>false</td><td>&quot;..a cocksure, stylized, gutty …</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;tyler_durden_dazzling_incredib…</td><td>&quot;Margaret Martin&quot;</td><td>false</td><td>&quot;A wild ride of a movie, Spring…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;glimmer_mythical_han_solo&quot;</td><td>&quot;Angel Peters&quot;</td><td>false</td><td>&quot;In a year of many car movies, …</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;gandalf_journey_epic&quot;</td><td>&quot;Alexandria Wilson&quot;</td><td>true</td><td>&quot;Festival will surely tickle yo…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;vito_corleone_lara_croft_travi…</td><td>&quot;Andrew Blankenship&quot;</td><td>false</td><td>&quot;The limp&amp;#44; negligible resul…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;golden_adventure_holly_golight…</td><td>&quot;Roberta Alexander&quot;</td><td>false</td><td>&quot;It may not send shivers up any…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;the_bride_zephyr_mystique&quot;</td><td>&quot;Karen Adams&quot;</td><td>false</td><td>&quot;Steven Spielberg&#x27;s new film is…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;destiny_valiant_dream&quot;</td><td>&quot;Nicholas Reynolds&quot;</td><td>false</td><td>&quot;It&#x27;s derivative as hell, but t…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;harry_potter_james_bond_jack_t…</td><td>&quot;Gary Vaughn&quot;</td><td>false</td><td>&quot;Doppelgangers have always been…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;v_dorothy_gale_crimson&quot;</td><td>&quot;Krista Lopez&quot;</td><td>false</td><td>&quot;The Wachowskis may have someth…</td><td>&quot;NEGATIVE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (16_275, 5)\n",
       "┌──────────────────────┬────────────────────┬────────────────────┬─────────────────────┬───────────┐\n",
       "│ movieid              ┆ reviewerName       ┆ isFrequentReviewer ┆ reviewText          ┆ sentiment │\n",
       "│ ---                  ┆ ---                ┆ ---                ┆ ---                 ┆ ---       │\n",
       "│ str                  ┆ str                ┆ bool               ┆ str                 ┆ str       │\n",
       "╞══════════════════════╪════════════════════╪════════════════════╪═════════════════════╪═══════════╡\n",
       "│ john_mcclane_rocky_b ┆ Deborah Farley     ┆ false              ┆ ..a cocksure,       ┆ POSITIVE  │\n",
       "│ alboa_laby…          ┆                    ┆                    ┆ stylized, gutty …   ┆           │\n",
       "│ tyler_durden_dazzlin ┆ Margaret Martin    ┆ false              ┆ A wild ride of a    ┆ POSITIVE  │\n",
       "│ g_incredib…          ┆                    ┆                    ┆ movie, Spring…      ┆           │\n",
       "│ glimmer_mythical_han ┆ Angel Peters       ┆ false              ┆ In a year of many   ┆ POSITIVE  │\n",
       "│ _solo                ┆                    ┆                    ┆ car movies, …       ┆           │\n",
       "│ gandalf_journey_epic ┆ Alexandria Wilson  ┆ true               ┆ Festival will       ┆ POSITIVE  │\n",
       "│                      ┆                    ┆                    ┆ surely tickle yo…   ┆           │\n",
       "│ vito_corleone_lara_c ┆ Andrew Blankenship ┆ false              ┆ The limp&#44;       ┆ NEGATIVE  │\n",
       "│ roft_travi…          ┆                    ┆                    ┆ negligible resul…   ┆           │\n",
       "│ …                    ┆ …                  ┆ …                  ┆ …                   ┆ …         │\n",
       "│ golden_adventure_hol ┆ Roberta Alexander  ┆ false              ┆ It may not send     ┆ POSITIVE  │\n",
       "│ ly_golight…          ┆                    ┆                    ┆ shivers up any…     ┆           │\n",
       "│ the_bride_zephyr_mys ┆ Karen Adams        ┆ false              ┆ Steven Spielberg's  ┆ POSITIVE  │\n",
       "│ tique                ┆                    ┆                    ┆ new film is…        ┆           │\n",
       "│ destiny_valiant_drea ┆ Nicholas Reynolds  ┆ false              ┆ It's derivative as  ┆ NEGATIVE  │\n",
       "│ m                    ┆                    ┆                    ┆ hell, but t…        ┆           │\n",
       "│ harry_potter_james_b ┆ Gary Vaughn        ┆ false              ┆ Doppelgangers have  ┆ NEGATIVE  │\n",
       "│ ond_jack_t…          ┆                    ┆                    ┆ always been…        ┆           │\n",
       "│ v_dorothy_gale_crims ┆ Krista Lopez       ┆ false              ┆ The Wachowskis may  ┆ NEGATIVE  │\n",
       "│ on                   ┆                    ┆                    ┆ have someth…        ┆           │\n",
       "└──────────────────────┴────────────────────┴────────────────────┴─────────────────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "# randomly select only 10% of the data since the dataset is large\n",
    "#RUN ONLY ONCE\n",
    "df_train = df_train.sample(fraction=0.1, shuffle=True, seed=42) \n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is for training. The sentiments are already labeled. This will allow us to train a model that can predict sentiments on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data 'punkt' already present.\n",
      "NLTK data 'stopwords' already present.\n",
      "Downloading NLTK data: wordnet...\n",
      "NLTK data 'wordnet' downloaded.\n",
      "Downloading NLTK data: omw-1.4...\n",
      "NLTK data 'omw-1.4' downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\meala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\meala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# here I have three python script I built to pre_process the data and running the pipeline\n",
    "# you can find the code in the tools/preprocess.py file\n",
    "# you can find  the code in the tools/pipeline.py file\n",
    "# the pre_process function is used to clean the text data, there are various options available, please check the tools/preprocess.py file for details\n",
    "# the run_pipeline function is used to run the sentimental analysis pipeline, it takes the training data and the vectorizer and machine learning methods as input, and returns the results\n",
    "from tools.preprocess import pre_process\n",
    "#this function will run the sentimental analysis in the training data and return the results\n",
    "from tools.pipeline import run_pipeline\n",
    "# this function will run the sentimental analysis in the new data and return the predictions\n",
    "from tools.predict import make_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a year of many car movies, this one was the best (Living Life Fearless)\n",
      "\n",
      "year many car movie one best living life fearless\n"
     ]
    }
   ],
   "source": [
    "# you can use the pre_process function to clean the text data\n",
    "response_column = \"reviewText\" # this is the column name for the text data, feel free to change it to your text column name\n",
    "sentiment_column = \"sentiment\" # this is the column name for the sentiment data, feel free to change it to your sentiment column name\n",
    "print(df_train[response_column][2])\n",
    "print(\"\\n\" + pre_process(df_train[response_column][2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_21836\\4018690164.py:5: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_train = df_train.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isFrequentReviewer</th><th>reviewText</th><th>sentiment</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;john_mcclane_rocky_balboa_laby…</td><td>&quot;Deborah Farley&quot;</td><td>false</td><td>&quot;..a cocksure, stylized, gutty …</td><td>&quot;POSITIVE&quot;</td><td>&quot;cocksure stylized gutty thrill…</td></tr><tr><td>&quot;tyler_durden_dazzling_incredib…</td><td>&quot;Margaret Martin&quot;</td><td>false</td><td>&quot;A wild ride of a movie, Spring…</td><td>&quot;POSITIVE&quot;</td><td>&quot;wild ride movie spring breaker…</td></tr><tr><td>&quot;glimmer_mythical_han_solo&quot;</td><td>&quot;Angel Peters&quot;</td><td>false</td><td>&quot;In a year of many car movies, …</td><td>&quot;POSITIVE&quot;</td><td>&quot;year many car movie one best l…</td></tr><tr><td>&quot;gandalf_journey_epic&quot;</td><td>&quot;Alexandria Wilson&quot;</td><td>true</td><td>&quot;Festival will surely tickle yo…</td><td>&quot;POSITIVE&quot;</td><td>&quot;festival surely tickle funny b…</td></tr><tr><td>&quot;vito_corleone_lara_croft_travi…</td><td>&quot;Andrew Blankenship&quot;</td><td>false</td><td>&quot;The limp&amp;#44; negligible resul…</td><td>&quot;NEGATIVE&quot;</td><td>&quot;limp 44 negligible result unwe…</td></tr><tr><td>&quot;zephyr_scarlett_o&#x27;hara_magicia…</td><td>&quot;Lee Griffin&quot;</td><td>false</td><td>&quot;The film does have it&#x27;s weak s…</td><td>&quot;POSITIVE&quot;</td><td>&quot;film weak spot part dead see&quot;</td></tr><tr><td>&quot;the_joker_quest_rocky_balboa&quot;</td><td>&quot;Brianna Flores&quot;</td><td>true</td><td>&quot;A good-hearted entertainment t…</td><td>&quot;POSITIVE&quot;</td><td>&quot;goodhearted entertainment mana…</td></tr><tr><td>&quot;surreal_the_captain_america_go…</td><td>&quot;Shelia Miller&quot;</td><td>false</td><td>&quot;At this moment, 500 Days of Su…</td><td>&quot;POSITIVE&quot;</td><td>&quot;moment 500 day summer favorite…</td></tr><tr><td>&quot;dorothy_gale_gollum_frodo_bagg…</td><td>&quot;Chelsea Martinez&quot;</td><td>false</td><td>&quot;Beats thrums with an unbridled…</td><td>&quot;POSITIVE&quot;</td><td>&quot;beat thrum unbridled energy ow…</td></tr><tr><td>&quot;phenomenal_valiant_michael_cor…</td><td>&quot;Mike Joseph&quot;</td><td>false</td><td>&quot;A sequel that - narratively an…</td><td>&quot;POSITIVE&quot;</td><td>&quot;sequel narratively visually se…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌─────────────────┬─────────────────┬────────────────┬────────────────┬───────────┬────────────────┐\n",
       "│ movieid         ┆ reviewerName    ┆ isFrequentRevi ┆ reviewText     ┆ sentiment ┆ processed      │\n",
       "│ ---             ┆ ---             ┆ ewer           ┆ ---            ┆ ---       ┆ ---            │\n",
       "│ str             ┆ str             ┆ ---            ┆ str            ┆ str       ┆ str            │\n",
       "│                 ┆                 ┆ bool           ┆                ┆           ┆                │\n",
       "╞═════════════════╪═════════════════╪════════════════╪════════════════╪═══════════╪════════════════╡\n",
       "│ john_mcclane_ro ┆ Deborah Farley  ┆ false          ┆ ..a cocksure,  ┆ POSITIVE  ┆ cocksure       │\n",
       "│ cky_balboa_laby ┆                 ┆                ┆ stylized,      ┆           ┆ stylized gutty │\n",
       "│ …               ┆                 ┆                ┆ gutty …        ┆           ┆ thrill…        │\n",
       "│ tyler_durden_da ┆ Margaret Martin ┆ false          ┆ A wild ride of ┆ POSITIVE  ┆ wild ride      │\n",
       "│ zzling_incredib ┆                 ┆                ┆ a movie,       ┆           ┆ movie spring   │\n",
       "│ …               ┆                 ┆                ┆ Spring…        ┆           ┆ breaker…       │\n",
       "│ glimmer_mythica ┆ Angel Peters    ┆ false          ┆ In a year of   ┆ POSITIVE  ┆ year many car  │\n",
       "│ l_han_solo      ┆                 ┆                ┆ many car       ┆           ┆ movie one best │\n",
       "│                 ┆                 ┆                ┆ movies, …      ┆           ┆ l…             │\n",
       "│ gandalf_journey ┆ Alexandria      ┆ true           ┆ Festival will  ┆ POSITIVE  ┆ festival       │\n",
       "│ _epic           ┆ Wilson          ┆                ┆ surely tickle  ┆           ┆ surely tickle  │\n",
       "│                 ┆                 ┆                ┆ yo…            ┆           ┆ funny b…       │\n",
       "│ vito_corleone_l ┆ Andrew          ┆ false          ┆ The limp&#44;  ┆ NEGATIVE  ┆ limp 44        │\n",
       "│ ara_croft_travi ┆ Blankenship     ┆                ┆ negligible     ┆           ┆ negligible     │\n",
       "│ …               ┆                 ┆                ┆ resul…         ┆           ┆ result unwe…   │\n",
       "│ zephyr_scarlett ┆ Lee Griffin     ┆ false          ┆ The film does  ┆ POSITIVE  ┆ film weak spot │\n",
       "│ _o'hara_magicia ┆                 ┆                ┆ have it's weak ┆           ┆ part dead see  │\n",
       "│ …               ┆                 ┆                ┆ s…             ┆           ┆                │\n",
       "│ the_joker_quest ┆ Brianna Flores  ┆ true           ┆ A good-hearted ┆ POSITIVE  ┆ goodhearted    │\n",
       "│ _rocky_balboa   ┆                 ┆                ┆ entertainment  ┆           ┆ entertainment  │\n",
       "│                 ┆                 ┆                ┆ t…             ┆           ┆ mana…          │\n",
       "│ surreal_the_cap ┆ Shelia Miller   ┆ false          ┆ At this        ┆ POSITIVE  ┆ moment 500 day │\n",
       "│ tain_america_go ┆                 ┆                ┆ moment, 500    ┆           ┆ summer         │\n",
       "│ …               ┆                 ┆                ┆ Days of Su…    ┆           ┆ favorite…      │\n",
       "│ dorothy_gale_go ┆ Chelsea         ┆ false          ┆ Beats thrums   ┆ POSITIVE  ┆ beat thrum     │\n",
       "│ llum_frodo_bagg ┆ Martinez        ┆                ┆ with an        ┆           ┆ unbridled      │\n",
       "│ …               ┆                 ┆                ┆ unbridled…     ┆           ┆ energy ow…     │\n",
       "│ phenomenal_vali ┆ Mike Joseph     ┆ false          ┆ A sequel that  ┆ POSITIVE  ┆ sequel         │\n",
       "│ ant_michael_cor ┆                 ┆                ┆ - narratively  ┆           ┆ narratively    │\n",
       "│ …               ┆                 ┆                ┆ an…            ┆           ┆ visually se…   │\n",
       "└─────────────────┴─────────────────┴────────────────┴────────────────┴───────────┴────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make changes as necessary\n",
    "# inside the map_elements, add  the parameters [pre_process(x, parameters_to_be_added)] and set it True/False if it differs from the defualt value\n",
    "# check the tools/preprocess.py file for the parameters and their default values\n",
    "# some of the parameters are remove_brackets, remove_stopwords, remove_punctuation, remove_numbers, remove_emojis, remove_urls, remove_html_tags, lemmatize, stem, lowercase\n",
    "df_train = df_train.with_columns(\n",
    "    pl.col(response_column).map_elements(lambda x: pre_process(x, remove_brackets=True)).alias(\"processed\")  #add inside the map_elements\n",
    ")\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are four text representation / vectorizer methods available \n",
    "#### in the function run_pipeline (in python cell below), we shall make use of this, write the words inside [ ] for the methods you want to use\n",
    "#### 1. Bag of Words [BOW] \n",
    "#### 2. Term Frequency [tf]\n",
    "#### 3. TF -IDF    [tfidf]\n",
    "#### 4. Word Embedding using Word2Vec (you can use other packages with slight changes) [wv] \n",
    "         # Word Embedding uses defualt 300 values; this will take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are also three machine learning methods that can be used\n",
    "#### 1. Logistic Regression [logit]\n",
    "#### 2. Random forest (recommended) (rf)\n",
    "#### 3. XGBoosting  [XGB](word embedding and XGBoost may take long time to complete, combination of both is not recommended in local machine)\n",
    "\n",
    "#I will keep this repository updated, and I will add more methods in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Pipeline for Wv + Logit ---\n",
      "WARNING: Dropped 651 rows due to missing values (None) in 'processed' or 'sentiment' columns. Original rows: 16275, Rows after dropping: 15624\n",
      "Labels encoded: Original -> ['NEGATIVE' 'POSITIVE'], Encoded -> [0 1]\n",
      "1. Vectorizing entire dataset (X)...\n",
      "Loading pre-trained word2vec-google-news-300 model (this may take a few minutes)...\n",
      "Word2Vec model loaded.\n",
      "2. Splitting data into train/test...\n",
      "3. Training and predicting...\n",
      "   - Starting Logistic Regression training with GridSearchCV for hyperparameter tuning...\n",
      "   - Using default parameter grid for tuning: {'solver': ['liblinear', 'lbfgs'], 'C': [0.1, 1.0, 10.0], 'class_weight': [None, 'balanced'], 'max_iter': [500, 1000]}\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "   - Best Hyperparameters found:\n",
      "{'C': 10.0, 'class_weight': None, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "   - Best Cross-Validation Score (F1-weighted): 0.7597\n",
      "Best model parameters: {'C': 10.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 500, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "4. Evaluating model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.70      0.53      0.61      1044\n",
      "    POSITIVE       0.79      0.89      0.84      2081\n",
      "\n",
      "    accuracy                           0.77      3125\n",
      "   macro avg       0.75      0.71      0.72      3125\n",
      "weighted avg       0.76      0.77      0.76      3125\n",
      "\n",
      "True labels distribution: Counter({1: 2081, 0: 1044})\n",
      "Predicted labels distribution: Counter({1: 2337, 0: 788})\n"
     ]
    }
   ],
   "source": [
    "# this is the example of how to use the function\n",
    "# you can change the vectorizer_name and model_name to the ones you want to use\n",
    "# for now we will use word embedding and logistic regression\n",
    "# write the name of your columns in the text_column_name and sentiment_column_name\n",
    "# the text_column_name is the column name of the text data, and sentiment_column_name is\n",
    "\n",
    "# run_pipeline function will return the dataframe with the vectorized text, vectorizer used  and the model\n",
    "# it will also print the results of the model, including the accuracy and F1 score\n",
    "# note, even without hyperparameter tuning, the model is getting over 70% accuracy in my test\n",
    "# there may not be a need to perform hyperparameter tuning, but you can set perform_tuning to True if you want to do that\n",
    "\n",
    "dt= run_pipeline(\n",
    "    vectorizer_name=\"wv\", # BOW, tf, tfidf, wv\n",
    "    model_name=\"logit\", # logit, rf, XGB .#XGB takes long time, can not recommend using it on normal case\n",
    "    df=df_train,\n",
    "    text_column_name=\"processed\",  # this is the column name of the text data, \n",
    "    sentiment_column_name = \"sentiment\",\n",
    "    perform_tuning = True # make this true if you want to perform hyperparameter tuning, it will take longer time and \n",
    "                            # may run out of memory if the dataset is large,\n",
    ")\n",
    "\n",
    "# missing values in the text data will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_object', 'vectorizer_name', 'vectorizer_object', 'label_encoder', 'y_test', 'y_pred', 'accuracy', 'report'])\n",
      "Vectorizer used:  wv\n",
      "Model used:  LogisticRegression(C=10.0, max_iter=500, random_state=42)\n",
      "Accuracy:  0.76896\n"
     ]
    }
   ],
   "source": [
    "## the dt is a dictionary that contains the results of the model, including the accuracy and F1 score\n",
    "print(dt.keys())\n",
    "# you can access the results using the keys of the dictionary\n",
    "print(\"Vectorizer used: \", dt[\"vectorizer_name\"])\n",
    "print(\"Model used: \", dt[\"model_object\"])\n",
    "print(\"Accuracy: \", dt[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Dataset for prediction\n",
    "You can use the same format as the training dataset, but ensure that it contains the \"Response\" column for text data. The \"Sentiment\" column is optional for prediction datasets, as it will be generated by the model.\n",
    "Make sure the dataset is saved in the \"New Data\" folder and is in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55315, 4)\n",
      "(13828, 4)\n"
     ]
    }
   ],
   "source": [
    "new_data = pl.read_csv(\"New Data/test.csv\",encoding='ISO-8859-1') #keep your file here\n",
    "print(new_data.shape)\n",
    "new_data= new_data.sample(fraction=0.25, shuffle=True, seed=42)\n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_21836\\3427585582.py:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  new_data = new_data.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isTopCritic</th><th>reviewText</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;frodo_baggins_rocky_balboa_she…</td><td>&quot;Toni Vaughn&quot;</td><td>false</td><td>&quot;The result is an unsettling ta…</td><td>&quot;result unsettling tale human p…</td></tr><tr><td>&quot;stardust_john_mcclane&quot;</td><td>&quot;Carol Jennings&quot;</td><td>false</td><td>&quot;Think twice about getting invo…</td><td>&quot;think twice getting involved w…</td></tr><tr><td>&quot;hermione_granger_sherlock_holm…</td><td>&quot;Tara Huang&quot;</td><td>true</td><td>&quot;A film that&#x27;s so bloody wonder…</td><td>&quot;film bloody wonderful meaning …</td></tr><tr><td>&quot;astonish_valiant&quot;</td><td>&quot;Shelley Murillo&quot;</td><td>false</td><td>&quot;...a decent setup that&#x27;s emplo…</td><td>&quot;decent setup employed progress…</td></tr><tr><td>&quot;indiana_jones_dazzling_dorothy…</td><td>&quot;Daniel Bond&quot;</td><td>false</td><td>&quot;Inspiring? Not to me. Lamentab…</td><td>&quot;inspiring lamentably bland exe…</td></tr><tr><td>&quot;glimmer_hannibal_lecter_frodo_…</td><td>&quot;Mrs. Nicole Fleming&quot;</td><td>false</td><td>&quot;This perfectly executed piece …</td><td>&quot;perfectly executed piece movie…</td></tr><tr><td>&quot;brave_anakin_skywalker&quot;</td><td>&quot;Melissa Harrington&quot;</td><td>false</td><td>&quot;The Richard Curtis script has …</td><td>&quot;richard curtis script rooney m…</td></tr><tr><td>&quot;katniss_everdeen_superman&quot;</td><td>&quot;Mckenzie Ortiz&quot;</td><td>false</td><td>&quot;A fun-filled afternoon of dino…</td><td>&quot;funfilled afternoon dinotastic…</td></tr><tr><td>&quot;secret_magic_john_wick_legend&quot;</td><td>&quot;Samantha Ware&quot;</td><td>false</td><td>&quot;I&#x27;m still not sure what this i…</td><td>&quot;still sure supposed save bunch…</td></tr><tr><td>&quot;gandalf_the_grey_magic_wandere…</td><td>&quot;Seth Downs&quot;</td><td>false</td><td>&quot;If the lizard ain&#x27;t broken, do…</td><td>&quot;lizard ai nt broken nt fix&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌─────────────────────┬────────────────────┬─────────────┬────────────────────┬────────────────────┐\n",
       "│ movieid             ┆ reviewerName       ┆ isTopCritic ┆ reviewText         ┆ processed          │\n",
       "│ ---                 ┆ ---                ┆ ---         ┆ ---                ┆ ---                │\n",
       "│ str                 ┆ str                ┆ bool        ┆ str                ┆ str                │\n",
       "╞═════════════════════╪════════════════════╪═════════════╪════════════════════╪════════════════════╡\n",
       "│ frodo_baggins_rocky ┆ Toni Vaughn        ┆ false       ┆ The result is an   ┆ result unsettling  │\n",
       "│ _balboa_she…        ┆                    ┆             ┆ unsettling ta…     ┆ tale human p…      │\n",
       "│ stardust_john_mccla ┆ Carol Jennings     ┆ false       ┆ Think twice about  ┆ think twice        │\n",
       "│ ne                  ┆                    ┆             ┆ getting invo…      ┆ getting involved   │\n",
       "│                     ┆                    ┆             ┆                    ┆ w…                 │\n",
       "│ hermione_granger_sh ┆ Tara Huang         ┆ true        ┆ A film that's so   ┆ film bloody        │\n",
       "│ erlock_holm…        ┆                    ┆             ┆ bloody wonder…     ┆ wonderful meaning  │\n",
       "│                     ┆                    ┆             ┆                    ┆ …                  │\n",
       "│ astonish_valiant    ┆ Shelley Murillo    ┆ false       ┆ ...a decent setup  ┆ decent setup       │\n",
       "│                     ┆                    ┆             ┆ that's emplo…      ┆ employed progress… │\n",
       "│ indiana_jones_dazzl ┆ Daniel Bond        ┆ false       ┆ Inspiring? Not to  ┆ inspiring          │\n",
       "│ ing_dorothy…        ┆                    ┆             ┆ me. Lamentab…      ┆ lamentably bland   │\n",
       "│                     ┆                    ┆             ┆                    ┆ exe…               │\n",
       "│ glimmer_hannibal_le ┆ Mrs. Nicole        ┆ false       ┆ This perfectly     ┆ perfectly executed │\n",
       "│ cter_frodo_…        ┆ Fleming            ┆             ┆ executed piece …   ┆ piece movie…       │\n",
       "│ brave_anakin_skywal ┆ Melissa Harrington ┆ false       ┆ The Richard Curtis ┆ richard curtis     │\n",
       "│ ker                 ┆                    ┆             ┆ script has …       ┆ script rooney m…   │\n",
       "│ katniss_everdeen_su ┆ Mckenzie Ortiz     ┆ false       ┆ A fun-filled       ┆ funfilled          │\n",
       "│ perman              ┆                    ┆             ┆ afternoon of dino… ┆ afternoon          │\n",
       "│                     ┆                    ┆             ┆                    ┆ dinotastic…        │\n",
       "│ secret_magic_john_w ┆ Samantha Ware      ┆ false       ┆ I'm still not sure ┆ still sure         │\n",
       "│ ick_legend          ┆                    ┆             ┆ what this i…       ┆ supposed save      │\n",
       "│                     ┆                    ┆             ┆                    ┆ bunch…             │\n",
       "│ gandalf_the_grey_ma ┆ Seth Downs         ┆ false       ┆ If the lizard      ┆ lizard ai nt       │\n",
       "│ gic_wandere…        ┆                    ┆             ┆ ain't broken, do…  ┆ broken nt fix      │\n",
       "└─────────────────────┴────────────────────┴─────────────┴────────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data.with_columns(\n",
    "    pl.col(response_column).map_elements(lambda x: pre_process(x, remove_brackets=True)).alias(\"processed\")  #add inside the map_elements\n",
    ")\n",
    "new_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13_181, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isTopCritic</th><th>reviewText</th><th>processed</th><th>sentiment_predictions</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;frodo_baggins_rocky_balboa_she…</td><td>&quot;Toni Vaughn&quot;</td><td>false</td><td>&quot;The result is an unsettling ta…</td><td>&quot;result unsettling tale human p…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;stardust_john_mcclane&quot;</td><td>&quot;Carol Jennings&quot;</td><td>false</td><td>&quot;Think twice about getting invo…</td><td>&quot;think twice getting involved w…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;hermione_granger_sherlock_holm…</td><td>&quot;Tara Huang&quot;</td><td>true</td><td>&quot;A film that&#x27;s so bloody wonder…</td><td>&quot;film bloody wonderful meaning …</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;astonish_valiant&quot;</td><td>&quot;Shelley Murillo&quot;</td><td>false</td><td>&quot;...a decent setup that&#x27;s emplo…</td><td>&quot;decent setup employed progress…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;indiana_jones_dazzling_dorothy…</td><td>&quot;Daniel Bond&quot;</td><td>false</td><td>&quot;Inspiring? Not to me. Lamentab…</td><td>&quot;inspiring lamentably bland exe…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;vivid_intrigue_celestial&quot;</td><td>&quot;Luke Reyes&quot;</td><td>false</td><td>&quot;This is the film&#x27;s ultimate me…</td><td>&quot;film ultimate message nt think…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;mystery_lost_james_t._kirk_sta…</td><td>&quot;Kathy Wade&quot;</td><td>false</td><td>&quot;It&#x27;s the best Sondheim adaptat…</td><td>&quot;best sondheim adaptation sayin…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;hiccup_terminator_myriad_capta…</td><td>&quot;Troy Watson&quot;</td><td>false</td><td>&quot;The South Australian actor her…</td><td>&quot;south australian actor deliver…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;rocky_balboa_dazzling_phantom&quot;</td><td>&quot;Wanda Peterson&quot;</td><td>true</td><td>&quot;Too slight to register as anyt…</td><td>&quot;slight register anything stunt…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;kingdom_adventure_vito_corleon…</td><td>&quot;Gina Powers&quot;</td><td>true</td><td>&quot;Nods to Jack Pierce&#x27;s iconic, …</td><td>&quot;nod jack pierce iconic karloff…</td><td>&quot;POSITIVE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13_181, 6)\n",
       "┌────────────────┬────────────────┬─────────────┬────────────────┬────────────────┬────────────────┐\n",
       "│ movieid        ┆ reviewerName   ┆ isTopCritic ┆ reviewText     ┆ processed      ┆ sentiment_pred │\n",
       "│ ---            ┆ ---            ┆ ---         ┆ ---            ┆ ---            ┆ ictions        │\n",
       "│ str            ┆ str            ┆ bool        ┆ str            ┆ str            ┆ ---            │\n",
       "│                ┆                ┆             ┆                ┆                ┆ str            │\n",
       "╞════════════════╪════════════════╪═════════════╪════════════════╪════════════════╪════════════════╡\n",
       "│ frodo_baggins_ ┆ Toni Vaughn    ┆ false       ┆ The result is  ┆ result         ┆ POSITIVE       │\n",
       "│ rocky_balboa_s ┆                ┆             ┆ an unsettling  ┆ unsettling     ┆                │\n",
       "│ he…            ┆                ┆             ┆ ta…            ┆ tale human p…  ┆                │\n",
       "│ stardust_john_ ┆ Carol Jennings ┆ false       ┆ Think twice    ┆ think twice    ┆ NEGATIVE       │\n",
       "│ mcclane        ┆                ┆             ┆ about getting  ┆ getting        ┆                │\n",
       "│                ┆                ┆             ┆ invo…          ┆ involved w…    ┆                │\n",
       "│ hermione_grang ┆ Tara Huang     ┆ true        ┆ A film that's  ┆ film bloody    ┆ POSITIVE       │\n",
       "│ er_sherlock_ho ┆                ┆             ┆ so bloody      ┆ wonderful      ┆                │\n",
       "│ lm…            ┆                ┆             ┆ wonder…        ┆ meaning …      ┆                │\n",
       "│ astonish_valia ┆ Shelley        ┆ false       ┆ ...a decent    ┆ decent setup   ┆ NEGATIVE       │\n",
       "│ nt             ┆ Murillo        ┆             ┆ setup that's   ┆ employed       ┆                │\n",
       "│                ┆                ┆             ┆ emplo…         ┆ progress…      ┆                │\n",
       "│ indiana_jones_ ┆ Daniel Bond    ┆ false       ┆ Inspiring? Not ┆ inspiring      ┆ NEGATIVE       │\n",
       "│ dazzling_dorot ┆                ┆             ┆ to me.         ┆ lamentably     ┆                │\n",
       "│ hy…            ┆                ┆             ┆ Lamentab…      ┆ bland exe…     ┆                │\n",
       "│ …              ┆ …              ┆ …           ┆ …              ┆ …              ┆ …              │\n",
       "│ vivid_intrigue ┆ Luke Reyes     ┆ false       ┆ This is the    ┆ film ultimate  ┆ POSITIVE       │\n",
       "│ _celestial     ┆                ┆             ┆ film's         ┆ message nt     ┆                │\n",
       "│                ┆                ┆             ┆ ultimate me…   ┆ think…         ┆                │\n",
       "│ mystery_lost_j ┆ Kathy Wade     ┆ false       ┆ It's the best  ┆ best sondheim  ┆ POSITIVE       │\n",
       "│ ames_t._kirk_s ┆                ┆             ┆ Sondheim       ┆ adaptation     ┆                │\n",
       "│ ta…            ┆                ┆             ┆ adaptat…       ┆ sayin…         ┆                │\n",
       "│ hiccup_termina ┆ Troy Watson    ┆ false       ┆ The South      ┆ south          ┆ POSITIVE       │\n",
       "│ tor_myriad_cap ┆                ┆             ┆ Australian     ┆ australian     ┆                │\n",
       "│ ta…            ┆                ┆             ┆ actor her…     ┆ actor deliver… ┆                │\n",
       "│ rocky_balboa_d ┆ Wanda Peterson ┆ true        ┆ Too slight to  ┆ slight         ┆ NEGATIVE       │\n",
       "│ azzling_phanto ┆                ┆             ┆ register as    ┆ register       ┆                │\n",
       "│ m              ┆                ┆             ┆ anyt…          ┆ anything       ┆                │\n",
       "│                ┆                ┆             ┆                ┆ stunt…         ┆                │\n",
       "│ kingdom_advent ┆ Gina Powers    ┆ true        ┆ Nods to Jack   ┆ nod jack       ┆ POSITIVE       │\n",
       "│ ure_vito_corle ┆                ┆             ┆ Pierce's       ┆ pierce iconic  ┆                │\n",
       "│ on…            ┆                ┆             ┆ iconic, …      ┆ karloff…       ┆                │\n",
       "└────────────────┴────────────────┴─────────────┴────────────────┴────────────────┴────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_predictions(\n",
    "    new_data=new_data,\n",
    "    text_column_name=\"processed\",\n",
    "    vectorizer=dt[\"vectorizer_object\"],\n",
    "    best_model=dt[\"model_object\"],\n",
    "    label_encoder=dt[\"label_encoder\"],\n",
    "    prediction_column_name=\"sentiment_predictions\"  # Optional custom name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
