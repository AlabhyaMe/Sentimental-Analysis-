{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the packages\n",
    "import polars as pl\n",
    "#make sure that this is the main file\n",
    "import sys\n",
    "import os\n",
    "project_root = os.getcwd()\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your data as Train.csv and place it in the Training Data folder. Or you can change the path in the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 162758 rows and 5 columns\n"
     ]
    }
   ],
   "source": [
    "# keep you training dataset in the training data folder\n",
    "# this template uses csv files \n",
    "# column names can be set in Python but this template does not automatically update the column for the demo \n",
    "# however, the function will give you the option to tell column names for the text and label data\n",
    "\n",
    "df_train = pl.read_csv(\"Training Data/Train.csv\",encoding='ISO-8859-1') \n",
    "print(f\"Dataset shape: {df_train.shape[0]} rows and {df_train.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_627, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isFrequentReviewer</th><th>reviewText</th><th>sentiment</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;glorious_starlight_v_dorothy_g…</td><td>&quot;Mandy Ponce&quot;</td><td>false</td><td>&quot;Superb acting adds weight to s…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;forrest_gump_whisper&quot;</td><td>&quot;Kelly Yang&quot;</td><td>false</td><td>&quot;Rust Creek just wants to tell …</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;journey_mystique_jason_bourne&quot;</td><td>&quot;Shelley Murillo&quot;</td><td>false</td><td>&quot;Vertical Limit is about as sil…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;james_t._kirk_ellis_redding_au…</td><td>&quot;Gwendolyn Guerra&quot;</td><td>false</td><td>&quot;The sort of production that co…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;gollum_norman_bates&quot;</td><td>&quot;Sharon Foster&quot;</td><td>false</td><td>&quot;[I]t might have benefited from…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;hulk_scarlett_o&#x27;hara_don_vito_…</td><td>&quot;Alicia Davila&quot;</td><td>false</td><td>&quot;Quite simply, Arrival is one o…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;epic_mythical_sherlock_holmes_…</td><td>&quot;Rebekah Henry&quot;</td><td>false</td><td>&quot;No matter how many A-Listers d…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;harry_potter_whirlwind_moonlit…</td><td>&quot;Mrs. Brenda Ferguson&quot;</td><td>true</td><td>&quot;Despite a lightness of plot, i…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;hulk_scarlett_o&#x27;hara_don_vito_…</td><td>&quot;Fernando Shepherd&quot;</td><td>true</td><td>&quot;An outstanding sci-fi film wit…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;captain_america_hannibal_lecte…</td><td>&quot;Dr. Heather Chan&quot;</td><td>false</td><td>&quot;Overall, News of the World is …</td><td>&quot;POSITIVE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_627, 5)\n",
       "┌─────────────────────┬─────────────────────┬────────────────────┬─────────────────────┬───────────┐\n",
       "│ movieid             ┆ reviewerName        ┆ isFrequentReviewer ┆ reviewText          ┆ sentiment │\n",
       "│ ---                 ┆ ---                 ┆ ---                ┆ ---                 ┆ ---       │\n",
       "│ str                 ┆ str                 ┆ bool               ┆ str                 ┆ str       │\n",
       "╞═════════════════════╪═════════════════════╪════════════════════╪═════════════════════╪═══════════╡\n",
       "│ glorious_starlight_ ┆ Mandy Ponce         ┆ false              ┆ Superb acting adds  ┆ POSITIVE  │\n",
       "│ v_dorothy_g…        ┆                     ┆                    ┆ weight to s…        ┆           │\n",
       "│ forrest_gump_whispe ┆ Kelly Yang          ┆ false              ┆ Rust Creek just     ┆ POSITIVE  │\n",
       "│ r                   ┆                     ┆                    ┆ wants to tell …     ┆           │\n",
       "│ journey_mystique_ja ┆ Shelley Murillo     ┆ false              ┆ Vertical Limit is   ┆ POSITIVE  │\n",
       "│ son_bourne          ┆                     ┆                    ┆ about as sil…       ┆           │\n",
       "│ james_t._kirk_ellis ┆ Gwendolyn Guerra    ┆ false              ┆ The sort of         ┆ NEGATIVE  │\n",
       "│ _redding_au…        ┆                     ┆                    ┆ production that co… ┆           │\n",
       "│ gollum_norman_bates ┆ Sharon Foster       ┆ false              ┆ [I]t might have     ┆ NEGATIVE  │\n",
       "│                     ┆                     ┆                    ┆ benefited from…     ┆           │\n",
       "│ …                   ┆ …                   ┆ …                  ┆ …                   ┆ …         │\n",
       "│ hulk_scarlett_o'har ┆ Alicia Davila       ┆ false              ┆ Quite simply,       ┆ POSITIVE  │\n",
       "│ a_don_vito_…        ┆                     ┆                    ┆ Arrival is one o…   ┆           │\n",
       "│ epic_mythical_sherl ┆ Rebekah Henry       ┆ false              ┆ No matter how many  ┆ NEGATIVE  │\n",
       "│ ock_holmes_…        ┆                     ┆                    ┆ A-Listers d…        ┆           │\n",
       "│ harry_potter_whirlw ┆ Mrs. Brenda         ┆ true               ┆ Despite a lightness ┆ POSITIVE  │\n",
       "│ ind_moonlit…        ┆ Ferguson            ┆                    ┆ of plot, i…         ┆           │\n",
       "│ hulk_scarlett_o'har ┆ Fernando Shepherd   ┆ true               ┆ An outstanding      ┆ POSITIVE  │\n",
       "│ a_don_vito_…        ┆                     ┆                    ┆ sci-fi film wit…    ┆           │\n",
       "│ captain_america_han ┆ Dr. Heather Chan    ┆ false              ┆ Overall, News of    ┆ POSITIVE  │\n",
       "│ nibal_lecte…        ┆                     ┆                    ┆ the World is …      ┆           │\n",
       "└─────────────────────┴─────────────────────┴────────────────────┴─────────────────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "# randomly select only 10% of the data since the dataset is large\n",
    "#RUN ONLY ONCE\n",
    "df_train = df_train.sample(fraction=0.1, shuffle=True, seed=42) \n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is for training. The sentiments are already labeled. This will allow us to train a model that can predict sentiments on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data 'punkt' already present.\n",
      "NLTK data 'stopwords' already present.\n",
      "Downloading NLTK data: wordnet...\n",
      "NLTK data 'wordnet' downloaded.\n",
      "Downloading NLTK data: omw-1.4...\n",
      "NLTK data 'omw-1.4' downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\meala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\meala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# here I have three python script I built to pre_process the data and running the pipeline\n",
    "# you can find the code in the tools/preprocess.py file\n",
    "# you can find  the code in the tools/pipeline.py file\n",
    "# the pre_process function is used to clean the text data, there are various options available, please check the tools/preprocess.py file for details\n",
    "# the run_pipeline function is used to run the sentimental analysis pipeline, it takes the training data and the vectorizer and machine learning methods as input, and returns the results\n",
    "from tools.preprocess import pre_process\n",
    "#this function will run the sentimental analysis in the training data and return the results\n",
    "from tools.pipeline import run_pipeline\n",
    "# this function will run the sentimental analysis in the new data and return the predictions\n",
    "from tools.predict import make_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical Limit is about as silly as movies come, but the only thing that really counts is whether or not the action sequences are exciting. And they are, in a big way.\n",
      "\n",
      "vertical limit silly movie come thing really count whether action sequence exciting big way\n"
     ]
    }
   ],
   "source": [
    "# you can use the pre_process function to clean the text data\n",
    "response_column = \"reviewText\" # this is the column name for the text data, feel free to change it to your text column name\n",
    "sentiment_column = \"sentiment\" # this is the column name for the sentiment data, feel free to change it to your sentiment column name\n",
    "print(df_train[response_column][2])\n",
    "print(\"\\n\" + pre_process(df_train[response_column][2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_6236\\2369074634.py:3: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_train = df_train.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isFrequentReviewer</th><th>reviewText</th><th>sentiment</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;glorious_starlight_v_dorothy_g…</td><td>&quot;Mandy Ponce&quot;</td><td>false</td><td>&quot;Superb acting adds weight to s…</td><td>&quot;POSITIVE&quot;</td><td>&quot;superb acting add weight scene…</td></tr><tr><td>&quot;forrest_gump_whisper&quot;</td><td>&quot;Kelly Yang&quot;</td><td>false</td><td>&quot;Rust Creek just wants to tell …</td><td>&quot;POSITIVE&quot;</td><td>&quot;rust creek want tell lean mean…</td></tr><tr><td>&quot;journey_mystique_jason_bourne&quot;</td><td>&quot;Shelley Murillo&quot;</td><td>false</td><td>&quot;Vertical Limit is about as sil…</td><td>&quot;POSITIVE&quot;</td><td>&quot;vertical limit silly movie com…</td></tr><tr><td>&quot;james_t._kirk_ellis_redding_au…</td><td>&quot;Gwendolyn Guerra&quot;</td><td>false</td><td>&quot;The sort of production that co…</td><td>&quot;NEGATIVE&quot;</td><td>&quot;sort production could performe…</td></tr><tr><td>&quot;gollum_norman_bates&quot;</td><td>&quot;Sharon Foster&quot;</td><td>false</td><td>&quot;[I]t might have benefited from…</td><td>&quot;NEGATIVE&quot;</td><td>&quot;might benefited little emotion…</td></tr><tr><td>&quot;fortune_the_terminator_t-800&quot;</td><td>&quot;Mallory Chung&quot;</td><td>false</td><td>&quot;...Egoyan&#x27;s &quot;Memento&quot; by way o…</td><td>&quot;POSITIVE&quot;</td><td>&quot;egoyan memento way must place …</td></tr><tr><td>&quot;rocky_balboa_forrest_gump&quot;</td><td>&quot;Jeffrey Garner&quot;</td><td>false</td><td>&quot;With Kingdom of Heaven, Ridley…</td><td>&quot;POSITIVE&quot;</td><td>&quot;kingdom heaven ridley prof goo…</td></tr><tr><td>&quot;spectacular_dorothy_gale_surre…</td><td>&quot;Don Hodges&quot;</td><td>true</td><td>&quot;A measured, deathly serious ep…</td><td>&quot;POSITIVE&quot;</td><td>&quot;measured deathly serious epic&quot;</td></tr><tr><td>&quot;golden_captain_america_beneath&quot;</td><td>&quot;Sarah Gray&quot;</td><td>false</td><td>&quot;As much as returning director …</td><td>&quot;NEGATIVE&quot;</td><td>&quot;much returning director adam r…</td></tr><tr><td>&quot;heroic_myriad_dracula_willy_wo…</td><td>&quot;Larry Greer&quot;</td><td>false</td><td>&quot;Reminds us how good romantic c…</td><td>&quot;POSITIVE&quot;</td><td>&quot;reminds u good romantic comedy…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌─────────────────┬─────────────────┬────────────────┬────────────────┬───────────┬────────────────┐\n",
       "│ movieid         ┆ reviewerName    ┆ isFrequentRevi ┆ reviewText     ┆ sentiment ┆ processed      │\n",
       "│ ---             ┆ ---             ┆ ewer           ┆ ---            ┆ ---       ┆ ---            │\n",
       "│ str             ┆ str             ┆ ---            ┆ str            ┆ str       ┆ str            │\n",
       "│                 ┆                 ┆ bool           ┆                ┆           ┆                │\n",
       "╞═════════════════╪═════════════════╪════════════════╪════════════════╪═══════════╪════════════════╡\n",
       "│ glorious_starli ┆ Mandy Ponce     ┆ false          ┆ Superb acting  ┆ POSITIVE  ┆ superb acting  │\n",
       "│ ght_v_dorothy_g ┆                 ┆                ┆ adds weight to ┆           ┆ add weight     │\n",
       "│ …               ┆                 ┆                ┆ s…             ┆           ┆ scene…         │\n",
       "│ forrest_gump_wh ┆ Kelly Yang      ┆ false          ┆ Rust Creek     ┆ POSITIVE  ┆ rust creek     │\n",
       "│ isper           ┆                 ┆                ┆ just wants to  ┆           ┆ want tell lean │\n",
       "│                 ┆                 ┆                ┆ tell …         ┆           ┆ mean…          │\n",
       "│ journey_mystiqu ┆ Shelley Murillo ┆ false          ┆ Vertical Limit ┆ POSITIVE  ┆ vertical limit │\n",
       "│ e_jason_bourne  ┆                 ┆                ┆ is about as    ┆           ┆ silly movie    │\n",
       "│                 ┆                 ┆                ┆ sil…           ┆           ┆ com…           │\n",
       "│ james_t._kirk_e ┆ Gwendolyn       ┆ false          ┆ The sort of    ┆ NEGATIVE  ┆ sort           │\n",
       "│ llis_redding_au ┆ Guerra          ┆                ┆ production     ┆           ┆ production     │\n",
       "│ …               ┆                 ┆                ┆ that co…       ┆           ┆ could          │\n",
       "│                 ┆                 ┆                ┆                ┆           ┆ performe…      │\n",
       "│ gollum_norman_b ┆ Sharon Foster   ┆ false          ┆ [I]t might     ┆ NEGATIVE  ┆ might          │\n",
       "│ ates            ┆                 ┆                ┆ have benefited ┆           ┆ benefited      │\n",
       "│                 ┆                 ┆                ┆ from…          ┆           ┆ little         │\n",
       "│                 ┆                 ┆                ┆                ┆           ┆ emotion…       │\n",
       "│ fortune_the_ter ┆ Mallory Chung   ┆ false          ┆ ...Egoyan's    ┆ POSITIVE  ┆ egoyan memento │\n",
       "│ minator_t-800   ┆                 ┆                ┆ \"Memento\" by   ┆           ┆ way must place │\n",
       "│                 ┆                 ┆                ┆ way o…         ┆           ┆ …              │\n",
       "│ rocky_balboa_fo ┆ Jeffrey Garner  ┆ false          ┆ With Kingdom   ┆ POSITIVE  ┆ kingdom heaven │\n",
       "│ rrest_gump      ┆                 ┆                ┆ of Heaven,     ┆           ┆ ridley prof    │\n",
       "│                 ┆                 ┆                ┆ Ridley…        ┆           ┆ goo…           │\n",
       "│ spectacular_dor ┆ Don Hodges      ┆ true           ┆ A measured,    ┆ POSITIVE  ┆ measured       │\n",
       "│ othy_gale_surre ┆                 ┆                ┆ deathly        ┆           ┆ deathly        │\n",
       "│ …               ┆                 ┆                ┆ serious ep…    ┆           ┆ serious epic   │\n",
       "│ golden_captain_ ┆ Sarah Gray      ┆ false          ┆ As much as     ┆ NEGATIVE  ┆ much returning │\n",
       "│ america_beneath ┆                 ┆                ┆ returning      ┆           ┆ director adam  │\n",
       "│                 ┆                 ┆                ┆ director …     ┆           ┆ r…             │\n",
       "│ heroic_myriad_d ┆ Larry Greer     ┆ false          ┆ Reminds us how ┆ POSITIVE  ┆ reminds u good │\n",
       "│ racula_willy_wo ┆                 ┆                ┆ good romantic  ┆           ┆ romantic       │\n",
       "│ …               ┆                 ┆                ┆ c…             ┆           ┆ comedy…        │\n",
       "└─────────────────┴─────────────────┴────────────────┴────────────────┴───────────┴────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make changes as necessary\n",
    "# inside the map_elements, add  the parameters [pre_process(x, parameters_to_be_added)] and set it True/False if it differs from the defualt value\n",
    "# check the tools/preprocess.py file for the parameters and their default values\n",
    "# some of the parameters are remove_brackets, remove_stopwords, remove_punctuation, remove_numbers, remove_emojis, remove_urls, remove_html_tags, lemmatize, stem, lowercase\n",
    "df_train = df_train.with_columns(\n",
    "    pl.col(response_column).map_elements(lambda x: pre_process(x, remove_brackets=True)).alias(\"processed\")  #add inside the map_elements\n",
    ")\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are four text representation / vectorizer methods available \n",
    "#### in the function run_pipeline (in python cell below), we shall make use of this, write the words inside [ ] for the methods you want to use\n",
    "#### 1. Bag of Words [BOW] \n",
    "#### 2. Term Frequency [tf]\n",
    "#### 3. TF -IDF    [tfidf]\n",
    "#### 4. Word Embedding using Word2Vec (you can use other packages with slight changes) [wv] \n",
    "         # Word Embedding uses defualt 300 values; this will take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are also three machine learning methods that can be used\n",
    "#### 1. Logistic Regression [logit]\n",
    "#### 2. Random forest (recommended) (rf)\n",
    "#### 3. XGBoosting  [XGB](word embedding and XGBoost may take long time to complete, combination of both is not recommended in local machine)\n",
    "\n",
    "#I will keep this repository updated, and I will add more methods in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Pipeline for Tf + Rf ---\n",
      "WARNING: Dropped 63 rows due to missing values (None) in 'processed' or 'sentiment' columns. Original rows: 1627, Rows after dropping: 1564\n",
      "Labels encoded: Original -> ['NEGATIVE' 'POSITIVE'], Encoded -> [0 1]\n",
      "1. Vectorizing entire dataset (X)...\n",
      "   - Generating TF features...\n",
      "2. Splitting data into train/test...\n",
      "3. Training and predicting...\n",
      "   - Starting Random Forest training with GridSearchCV for hyperparameter tuning...\n",
      "   - Using default parameter grid for tuning: {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'class_weight': [None, 'balanced']}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# this is the example of how to use the function\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# you can change the vectorizer_name and model_name to the ones you want to use\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# for now we will use word embedding and logistic regression\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# it will also print the results of the model, including the accuracy and F1 score\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# note, even without hyperparameter tuning, the model is getting over 70% accuracy \u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m dt\u001b[38;5;241m=\u001b[39m run_pipeline(\n\u001b[0;32m     11\u001b[0m     vectorizer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# BOW, tf, tfidf, wv\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# logit, rf, XGB .#XGB takes long time, can not recommend using it on normal case\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf_train,\n\u001b[0;32m     14\u001b[0m     text_column_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# this is the column name of the text data, \u001b[39;00m\n\u001b[0;32m     15\u001b[0m     sentiment_column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     perform_tuning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# make this true if you want to perform hyperparameter tuning, it will take longer time and \u001b[39;00m\n\u001b[0;32m     17\u001b[0m                             \u001b[38;5;66;03m# may run out of memory if the dataset is large,\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\meala\\Dropbox\\Data Work\\Text NLP\\tools\\pipeline.py:98\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[1;34m(vectorizer_name, model_name, df, text_column_name, sentiment_column_name, perform_tuning)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Train + predict\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. Training and predicting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m y_pred, trained_model_object \u001b[38;5;241m=\u001b[39m train_and_predict_function(X_train, y_train, X_test, perform_tuning\u001b[38;5;241m=\u001b[39mperform_tuning)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. Evaluating model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\meala\\Dropbox\\Data Work\\Text NLP\\MLAlgo\\rf.py:49\u001b[0m, in \u001b[0;36mtrain_and_predict\u001b[1;34m(X_train, y_train, X_test, perform_tuning)\u001b[0m\n\u001b[0;32m     39\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     40\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf_model, \u001b[38;5;66;03m# Use the base rf_model here\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Fit GridSearchCV to the training data\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Get the best model found by GridSearchCV\u001b[39;00m\n\u001b[0;32m     52\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1359\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m ):\n\u001b[1;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1089\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1087\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1089\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1091\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1359\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m ):\n\u001b[1;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    475\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    478\u001b[0m ]\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    487\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    488\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    489\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    490\u001b[0m )(\n\u001b[0;32m    491\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    492\u001b[0m         t,\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    494\u001b[0m         X,\n\u001b[0;32m    495\u001b[0m         y,\n\u001b[0;32m    496\u001b[0m         sample_weight,\n\u001b[0;32m    497\u001b[0m         i,\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    499\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    500\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    501\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    502\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config_and_warning_filters)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    189\u001b[0m         X,\n\u001b[0;32m    190\u001b[0m         y,\n\u001b[0;32m    191\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    192\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    193\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    194\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    197\u001b[0m         X,\n\u001b[0;32m    198\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# this is the example of how to use the function\n",
    "# you can change the vectorizer_name and model_name to the ones you want to use\n",
    "# for now we will use word embedding and logistic regression\n",
    "# write the name of your columns in the text_column_name and sentiment_column_name\n",
    "# the text_column_name is the column name of the text data, and sentiment_column_name is\n",
    "\n",
    "# run_pipeline function will return the dataframe with the vectorized text, vectorizer used  and the model\n",
    "# it will also print the results of the model, including the accuracy and F1 score\n",
    "# note, even without hyperparameter tuning, the model is getting over 70% accuracy in my test\n",
    "# there may not be a need to perform hyperparameter tuning, but you can set perform_tuning to True if you want to do that\n",
    "\n",
    "dt= run_pipeline(\n",
    "    vectorizer_name=\"wv\", # BOW, tf, tfidf, wv\n",
    "    model_name=\"logit\", # logit, rf, XGB .#XGB takes long time, can not recommend using it on normal case\n",
    "    df=df_train,\n",
    "    text_column_name=\"processed\",  # this is the column name of the text data, \n",
    "    sentiment_column_name = \"sentiment\",\n",
    "    perform_tuning = True # make this true if you want to perform hyperparameter tuning, it will take longer time and \n",
    "                            # may run out of memory if the dataset is large,\n",
    ")\n",
    "\n",
    "# missing values in the text data will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_object', 'vectorizer_name', 'vectorizer_object', 'label_encoder', 'y_test', 'y_pred', 'accuracy', 'report'])\n",
      "Vectorizer used:  tf\n",
      "Model used:  LogisticRegression(random_state=42)\n",
      "Accuracy:  0.6768\n"
     ]
    }
   ],
   "source": [
    "## the dt is a dictionary that contains the results of the model, including the accuracy and F1 score\n",
    "print(dt.keys())\n",
    "# you can access the results using the keys of the dictionary\n",
    "print(\"Vectorizer used: \", dt[\"vectorizer_name\"])\n",
    "print(\"Model used: \", dt[\"model_object\"])\n",
    "print(\"Accuracy: \", dt[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Dataset for prediction\n",
    "You can use the same format as the training dataset, but ensure that it contains the \"Response\" column for text data. The \"Sentiment\" column is optional for prediction datasets, as it will be generated by the model.\n",
    "Make sure the dataset is saved in the \"New Data\" folder and is in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55315, 4)\n",
      "(13828, 4)\n"
     ]
    }
   ],
   "source": [
    "new_data = pl.read_csv(\"New Data/test.csv\",encoding='ISO-8859-1') #keep your file here\n",
    "print(new_data.shape)\n",
    "new_data= new_data.sample(fraction=0.25, shuffle=True, seed=42)\n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_21112\\3427585582.py:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  new_data = new_data.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isTopCritic</th><th>reviewText</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;frodo_baggins_rocky_balboa_she…</td><td>&quot;Toni Vaughn&quot;</td><td>false</td><td>&quot;The result is an unsettling ta…</td><td>&quot;result unsettling tale human p…</td></tr><tr><td>&quot;stardust_john_mcclane&quot;</td><td>&quot;Carol Jennings&quot;</td><td>false</td><td>&quot;Think twice about getting invo…</td><td>&quot;think twice getting involved w…</td></tr><tr><td>&quot;hermione_granger_sherlock_holm…</td><td>&quot;Tara Huang&quot;</td><td>true</td><td>&quot;A film that&#x27;s so bloody wonder…</td><td>&quot;film bloody wonderful meaning …</td></tr><tr><td>&quot;astonish_valiant&quot;</td><td>&quot;Shelley Murillo&quot;</td><td>false</td><td>&quot;...a decent setup that&#x27;s emplo…</td><td>&quot;decent setup employed progress…</td></tr><tr><td>&quot;indiana_jones_dazzling_dorothy…</td><td>&quot;Daniel Bond&quot;</td><td>false</td><td>&quot;Inspiring? Not to me. Lamentab…</td><td>&quot;inspiring lamentably bland exe…</td></tr><tr><td>&quot;glimmer_hannibal_lecter_frodo_…</td><td>&quot;Mrs. Nicole Fleming&quot;</td><td>false</td><td>&quot;This perfectly executed piece …</td><td>&quot;perfectly executed piece movie…</td></tr><tr><td>&quot;brave_anakin_skywalker&quot;</td><td>&quot;Melissa Harrington&quot;</td><td>false</td><td>&quot;The Richard Curtis script has …</td><td>&quot;richard curtis script rooney m…</td></tr><tr><td>&quot;katniss_everdeen_superman&quot;</td><td>&quot;Mckenzie Ortiz&quot;</td><td>false</td><td>&quot;A fun-filled afternoon of dino…</td><td>&quot;funfilled afternoon dinotastic…</td></tr><tr><td>&quot;secret_magic_john_wick_legend&quot;</td><td>&quot;Samantha Ware&quot;</td><td>false</td><td>&quot;I&#x27;m still not sure what this i…</td><td>&quot;still sure supposed save bunch…</td></tr><tr><td>&quot;gandalf_the_grey_magic_wandere…</td><td>&quot;Seth Downs&quot;</td><td>false</td><td>&quot;If the lizard ain&#x27;t broken, do…</td><td>&quot;lizard ai nt broken nt fix&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌─────────────────────┬────────────────────┬─────────────┬────────────────────┬────────────────────┐\n",
       "│ movieid             ┆ reviewerName       ┆ isTopCritic ┆ reviewText         ┆ processed          │\n",
       "│ ---                 ┆ ---                ┆ ---         ┆ ---                ┆ ---                │\n",
       "│ str                 ┆ str                ┆ bool        ┆ str                ┆ str                │\n",
       "╞═════════════════════╪════════════════════╪═════════════╪════════════════════╪════════════════════╡\n",
       "│ frodo_baggins_rocky ┆ Toni Vaughn        ┆ false       ┆ The result is an   ┆ result unsettling  │\n",
       "│ _balboa_she…        ┆                    ┆             ┆ unsettling ta…     ┆ tale human p…      │\n",
       "│ stardust_john_mccla ┆ Carol Jennings     ┆ false       ┆ Think twice about  ┆ think twice        │\n",
       "│ ne                  ┆                    ┆             ┆ getting invo…      ┆ getting involved   │\n",
       "│                     ┆                    ┆             ┆                    ┆ w…                 │\n",
       "│ hermione_granger_sh ┆ Tara Huang         ┆ true        ┆ A film that's so   ┆ film bloody        │\n",
       "│ erlock_holm…        ┆                    ┆             ┆ bloody wonder…     ┆ wonderful meaning  │\n",
       "│                     ┆                    ┆             ┆                    ┆ …                  │\n",
       "│ astonish_valiant    ┆ Shelley Murillo    ┆ false       ┆ ...a decent setup  ┆ decent setup       │\n",
       "│                     ┆                    ┆             ┆ that's emplo…      ┆ employed progress… │\n",
       "│ indiana_jones_dazzl ┆ Daniel Bond        ┆ false       ┆ Inspiring? Not to  ┆ inspiring          │\n",
       "│ ing_dorothy…        ┆                    ┆             ┆ me. Lamentab…      ┆ lamentably bland   │\n",
       "│                     ┆                    ┆             ┆                    ┆ exe…               │\n",
       "│ glimmer_hannibal_le ┆ Mrs. Nicole        ┆ false       ┆ This perfectly     ┆ perfectly executed │\n",
       "│ cter_frodo_…        ┆ Fleming            ┆             ┆ executed piece …   ┆ piece movie…       │\n",
       "│ brave_anakin_skywal ┆ Melissa Harrington ┆ false       ┆ The Richard Curtis ┆ richard curtis     │\n",
       "│ ker                 ┆                    ┆             ┆ script has …       ┆ script rooney m…   │\n",
       "│ katniss_everdeen_su ┆ Mckenzie Ortiz     ┆ false       ┆ A fun-filled       ┆ funfilled          │\n",
       "│ perman              ┆                    ┆             ┆ afternoon of dino… ┆ afternoon          │\n",
       "│                     ┆                    ┆             ┆                    ┆ dinotastic…        │\n",
       "│ secret_magic_john_w ┆ Samantha Ware      ┆ false       ┆ I'm still not sure ┆ still sure         │\n",
       "│ ick_legend          ┆                    ┆             ┆ what this i…       ┆ supposed save      │\n",
       "│                     ┆                    ┆             ┆                    ┆ bunch…             │\n",
       "│ gandalf_the_grey_ma ┆ Seth Downs         ┆ false       ┆ If the lizard      ┆ lizard ai nt       │\n",
       "│ gic_wandere…        ┆                    ┆             ┆ ain't broken, do…  ┆ broken nt fix      │\n",
       "└─────────────────────┴────────────────────┴─────────────┴────────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data.with_columns(\n",
    "    pl.col(response_column).map_elements(lambda x: pre_process(x, remove_brackets=True)).alias(\"processed\")  #add inside the map_elements\n",
    ")\n",
    "new_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13_181, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isTopCritic</th><th>reviewText</th><th>processed</th><th>sentiment_predictions</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;frodo_baggins_rocky_balboa_she…</td><td>&quot;Toni Vaughn&quot;</td><td>false</td><td>&quot;The result is an unsettling ta…</td><td>&quot;result unsettling tale human p…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;stardust_john_mcclane&quot;</td><td>&quot;Carol Jennings&quot;</td><td>false</td><td>&quot;Think twice about getting invo…</td><td>&quot;think twice getting involved w…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;hermione_granger_sherlock_holm…</td><td>&quot;Tara Huang&quot;</td><td>true</td><td>&quot;A film that&#x27;s so bloody wonder…</td><td>&quot;film bloody wonderful meaning …</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;astonish_valiant&quot;</td><td>&quot;Shelley Murillo&quot;</td><td>false</td><td>&quot;...a decent setup that&#x27;s emplo…</td><td>&quot;decent setup employed progress…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;indiana_jones_dazzling_dorothy…</td><td>&quot;Daniel Bond&quot;</td><td>false</td><td>&quot;Inspiring? Not to me. Lamentab…</td><td>&quot;inspiring lamentably bland exe…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;vivid_intrigue_celestial&quot;</td><td>&quot;Luke Reyes&quot;</td><td>false</td><td>&quot;This is the film&#x27;s ultimate me…</td><td>&quot;film ultimate message nt think…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;mystery_lost_james_t._kirk_sta…</td><td>&quot;Kathy Wade&quot;</td><td>false</td><td>&quot;It&#x27;s the best Sondheim adaptat…</td><td>&quot;best sondheim adaptation sayin…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;hiccup_terminator_myriad_capta…</td><td>&quot;Troy Watson&quot;</td><td>false</td><td>&quot;The South Australian actor her…</td><td>&quot;south australian actor deliver…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;rocky_balboa_dazzling_phantom&quot;</td><td>&quot;Wanda Peterson&quot;</td><td>true</td><td>&quot;Too slight to register as anyt…</td><td>&quot;slight register anything stunt…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;kingdom_adventure_vito_corleon…</td><td>&quot;Gina Powers&quot;</td><td>true</td><td>&quot;Nods to Jack Pierce&#x27;s iconic, …</td><td>&quot;nod jack pierce iconic karloff…</td><td>&quot;POSITIVE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13_181, 6)\n",
       "┌────────────────┬────────────────┬─────────────┬────────────────┬────────────────┬────────────────┐\n",
       "│ movieid        ┆ reviewerName   ┆ isTopCritic ┆ reviewText     ┆ processed      ┆ sentiment_pred │\n",
       "│ ---            ┆ ---            ┆ ---         ┆ ---            ┆ ---            ┆ ictions        │\n",
       "│ str            ┆ str            ┆ bool        ┆ str            ┆ str            ┆ ---            │\n",
       "│                ┆                ┆             ┆                ┆                ┆ str            │\n",
       "╞════════════════╪════════════════╪═════════════╪════════════════╪════════════════╪════════════════╡\n",
       "│ frodo_baggins_ ┆ Toni Vaughn    ┆ false       ┆ The result is  ┆ result         ┆ POSITIVE       │\n",
       "│ rocky_balboa_s ┆                ┆             ┆ an unsettling  ┆ unsettling     ┆                │\n",
       "│ he…            ┆                ┆             ┆ ta…            ┆ tale human p…  ┆                │\n",
       "│ stardust_john_ ┆ Carol Jennings ┆ false       ┆ Think twice    ┆ think twice    ┆ NEGATIVE       │\n",
       "│ mcclane        ┆                ┆             ┆ about getting  ┆ getting        ┆                │\n",
       "│                ┆                ┆             ┆ invo…          ┆ involved w…    ┆                │\n",
       "│ hermione_grang ┆ Tara Huang     ┆ true        ┆ A film that's  ┆ film bloody    ┆ NEGATIVE       │\n",
       "│ er_sherlock_ho ┆                ┆             ┆ so bloody      ┆ wonderful      ┆                │\n",
       "│ lm…            ┆                ┆             ┆ wonder…        ┆ meaning …      ┆                │\n",
       "│ astonish_valia ┆ Shelley        ┆ false       ┆ ...a decent    ┆ decent setup   ┆ NEGATIVE       │\n",
       "│ nt             ┆ Murillo        ┆             ┆ setup that's   ┆ employed       ┆                │\n",
       "│                ┆                ┆             ┆ emplo…         ┆ progress…      ┆                │\n",
       "│ indiana_jones_ ┆ Daniel Bond    ┆ false       ┆ Inspiring? Not ┆ inspiring      ┆ NEGATIVE       │\n",
       "│ dazzling_dorot ┆                ┆             ┆ to me.         ┆ lamentably     ┆                │\n",
       "│ hy…            ┆                ┆             ┆ Lamentab…      ┆ bland exe…     ┆                │\n",
       "│ …              ┆ …              ┆ …           ┆ …              ┆ …              ┆ …              │\n",
       "│ vivid_intrigue ┆ Luke Reyes     ┆ false       ┆ This is the    ┆ film ultimate  ┆ NEGATIVE       │\n",
       "│ _celestial     ┆                ┆             ┆ film's         ┆ message nt     ┆                │\n",
       "│                ┆                ┆             ┆ ultimate me…   ┆ think…         ┆                │\n",
       "│ mystery_lost_j ┆ Kathy Wade     ┆ false       ┆ It's the best  ┆ best sondheim  ┆ POSITIVE       │\n",
       "│ ames_t._kirk_s ┆                ┆             ┆ Sondheim       ┆ adaptation     ┆                │\n",
       "│ ta…            ┆                ┆             ┆ adaptat…       ┆ sayin…         ┆                │\n",
       "│ hiccup_termina ┆ Troy Watson    ┆ false       ┆ The South      ┆ south          ┆ NEGATIVE       │\n",
       "│ tor_myriad_cap ┆                ┆             ┆ Australian     ┆ australian     ┆                │\n",
       "│ ta…            ┆                ┆             ┆ actor her…     ┆ actor deliver… ┆                │\n",
       "│ rocky_balboa_d ┆ Wanda Peterson ┆ true        ┆ Too slight to  ┆ slight         ┆ NEGATIVE       │\n",
       "│ azzling_phanto ┆                ┆             ┆ register as    ┆ register       ┆                │\n",
       "│ m              ┆                ┆             ┆ anyt…          ┆ anything       ┆                │\n",
       "│                ┆                ┆             ┆                ┆ stunt…         ┆                │\n",
       "│ kingdom_advent ┆ Gina Powers    ┆ true        ┆ Nods to Jack   ┆ nod jack       ┆ POSITIVE       │\n",
       "│ ure_vito_corle ┆                ┆             ┆ Pierce's       ┆ pierce iconic  ┆                │\n",
       "│ on…            ┆                ┆             ┆ iconic, …      ┆ karloff…       ┆                │\n",
       "└────────────────┴────────────────┴─────────────┴────────────────┴────────────────┴────────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_predictions(\n",
    "    new_data=new_data,\n",
    "    text_column_name=\"processed\",\n",
    "    vectorizer=dt[\"vectorizer_object\"],\n",
    "    best_model=dt[\"model_object\"],\n",
    "    label_encoder=dt[\"label_encoder\"],\n",
    "    prediction_column_name=\"sentiment_predictions\"  # Optional custom name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
