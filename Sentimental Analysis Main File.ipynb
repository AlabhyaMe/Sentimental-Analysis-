{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the packages \n",
    "#%pip install nltk\n",
    "#%pip install polars\n",
    "#%pip install gensim\n",
    "#%pip install emoji\n",
    "\n",
    "#this is required for the first time\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the packages\n",
    "import polars as pl\n",
    "#make sure that this is the main file\n",
    "import sys\n",
    "import os\n",
    "project_root = os.getcwd()\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep you training dataset in the training data folder\n",
    "# this template uses csv files\n",
    "# for the demo, the response and the sentiments are named Response and Sentiment respectively in the csv file. \n",
    "# column names can be set in Python but this template does not automatically update the column for the demo\n",
    "# however, the function will give you the option to tell column names for the text and label data\n",
    "\n",
    "df_train = pl.read_csv(\"Training Data\\Train.csv\",encoding='ISO-8859-1') \n",
    "#Replace the name \"Train.csv\" with your file name | alternatively, rename your file name as \"Train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Response</th><th>Sentiment</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;[NAME] I handicap Disable disa…</td><td>&quot;O&quot;</td></tr><tr><td>&quot;[NAME] I will clean the hospit…</td><td>&quot;O&quot;</td></tr><tr><td>&quot;1. There are no clear instruct…</td><td>&quot;N&quot;</td></tr><tr><td>&quot;2 times i left messages and ne…</td><td>&quot;O&quot;</td></tr><tr><td>&quot;A bit confusing st first,&nbsp;&nbsp;but…</td><td>&quot;P&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ Response                        ┆ Sentiment │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ str       │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ [NAME] I handicap Disable disa… ┆ O         │\n",
       "│ [NAME] I will clean the hospit… ┆ O         │\n",
       "│ 1. There are no clear instruct… ┆ N         │\n",
       "│ 2 times i left messages and ne… ┆ O         │\n",
       "│ A bit confusing st first,  but… ┆ P         │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools.preprocess module loaded\n",
      "Functions available in module: ['WordNetLemmatizer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'emoji', 'lemmatizer', 'numpy', 'pre_process', 're', 'remove_emojis', 'remove_extra_spaces', 'remove_html_tags', 'remove_numbers', 'remove_punctuation_from_token', 'remove_square_brackets', 'remove_urls_emails', 'simple_tokenizer', 'stop_words', 'stopwords', 'string', 'word_tokenize']\n"
     ]
    }
   ],
   "source": [
    "# here I have two python script I built to pre_process the data and running the pipeline\n",
    "# you can find the code in the tools/preprocess.py file\n",
    "# you can find  the code in the tools/pipeline.py file\n",
    "# the pre_process function is used to clean the text data, there are various options available, please check the tools/preprocess.py file for details\n",
    "# the run_pipeline function is used to run the sentimental analysis pipeline, it takes the training data and the vectorizer and machine learning methods as input, and returns the results\n",
    "import importlib\n",
    "from tools.preprocess import pre_process\n",
    "#this function will run the sentimental analysis in the training data and return the results\n",
    "from tools.pipeline import run_pipeline\n",
    "# this function will run the sentimental analysis in the new data and return the predictions\n",
    "from tools.predict import predict_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"[NAME] I handicap Disable disabled Special I work Aha says it's a [ADDRESS] [PHONE NUMBER]\",\n",
       " 'name handicap disable disabled special work aha say address phone number',\n",
       " 'handicap disable disabled special work aha say')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use the pre_process function to clean the text data\n",
    "df_train[\"Response\"][0] , pre_process(df_train[\"Response\"][0]) , pre_process(df_train[\"Response\"][0],remove_brackets= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_27760\\2777744706.py:3: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_train = df_train.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Response</th><th>Sentiment</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;[NAME] I handicap Disable disa…</td><td>&quot;O&quot;</td><td>&quot;handicap disable disabled spec…</td></tr><tr><td>&quot;[NAME] I will clean the hospit…</td><td>&quot;O&quot;</td><td>&quot;clean hospital hide hospital s…</td></tr><tr><td>&quot;1. There are no clear instruct…</td><td>&quot;N&quot;</td><td>&quot;1 clear instruction extending …</td></tr><tr><td>&quot;2 times i left messages and ne…</td><td>&quot;O&quot;</td><td>&quot;2 time left message never rece…</td></tr><tr><td>&quot;A bit confusing st first,&nbsp;&nbsp;but…</td><td>&quot;P&quot;</td><td>&quot;bit confusing st first using t…</td></tr><tr><td>&quot;A excellent process that helps…</td><td>&quot;P&quot;</td><td>&quot;excellent process help navigat…</td></tr><tr><td>&quot;A little confused with checkin…</td><td>&quot;O&quot;</td><td>&quot;little confused checking thru …</td></tr><tr><td>&quot;A little hard to navigate&quot;</td><td>&quot;N&quot;</td><td>&quot;little hard navigate&quot;</td></tr><tr><td>&quot;A lot of the time the website …</td><td>&quot;N&quot;</td><td>&quot;lot time website website easy …</td></tr><tr><td>&quot;A surprisingly easy website to…</td><td>&quot;P&quot;</td><td>&quot;surprisingly easy website navi…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌─────────────────────────────────┬───────────┬─────────────────────────────────┐\n",
       "│ Response                        ┆ Sentiment ┆ processed                       │\n",
       "│ ---                             ┆ ---       ┆ ---                             │\n",
       "│ str                             ┆ str       ┆ str                             │\n",
       "╞═════════════════════════════════╪═══════════╪═════════════════════════════════╡\n",
       "│ [NAME] I handicap Disable disa… ┆ O         ┆ handicap disable disabled spec… │\n",
       "│ [NAME] I will clean the hospit… ┆ O         ┆ clean hospital hide hospital s… │\n",
       "│ 1. There are no clear instruct… ┆ N         ┆ 1 clear instruction extending … │\n",
       "│ 2 times i left messages and ne… ┆ O         ┆ 2 time left message never rece… │\n",
       "│ A bit confusing st first,  but… ┆ P         ┆ bit confusing st first using t… │\n",
       "│ A excellent process that helps… ┆ P         ┆ excellent process help navigat… │\n",
       "│ A little confused with checkin… ┆ O         ┆ little confused checking thru … │\n",
       "│ A little hard to navigate       ┆ N         ┆ little hard navigate            │\n",
       "│ A lot of the time the website … ┆ N         ┆ lot time website website easy … │\n",
       "│ A surprisingly easy website to… ┆ P         ┆ surprisingly easy website navi… │\n",
       "└─────────────────────────────────┴───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make changes as necessary\n",
    "# inside the map_elements, add  the parameters [pre_process(x, parameters_to_be_added)] and set it True/False if it differs from the defualt value\n",
    "df_train = df_train.with_columns(\n",
    "    pl.col(\"Response\").map_elements(lambda x: pre_process(x, remove_brackets=True)).alias(\"processed\")  #add inside the map_elements\n",
    ")\n",
    "df_train.head(10)\n",
    "#output might show warnings, it usually is not any problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are four text representation / vectorizer methods available \n",
    "#### #in the function run_pipeline, we shall make use of this, write the words inside [ ] for the methods you want to use\n",
    "#### 1. Bag of Words [BOW] \n",
    "#### 2. Term Frequency [tf]\n",
    "#### 3. TF -IDF    [tfidf]\n",
    "#### 4. Word Embedding using Word2Vec (you can use other packages with slight changes) [wv] \n",
    "         # Word Embedding uses defualt 300 values; this will take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are also three machine learning methods that can be used\n",
    "#### 1. Logistic Regression [logit]\n",
    "#### 2. Random forest (recommended) (rf)\n",
    "#### 3. XGBoosting  [XGB](word embedding and XGBoost may take long time to complete, combination of both is not recommended in local machine)\n",
    "\n",
    "#I will keep this repository updated, and I will add more methods in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Pipeline for Wv + Logit ---\n",
      "Labels encoded: Original -> ['N' 'O' 'P'], Encoded -> [0 1 2]\n",
      "1. Vectorizing entire dataset (X)...\n",
      "Loading pre-trained word2vec-google-news-300 model (this may take a few minutes)...\n",
      "Word2Vec model loaded.\n",
      "2. Splitting data into train/test...\n",
      "3. Training and predicting...\n",
      "   - Starting Logistic Regression training with GridSearchCV for hyperparameter tuning...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - Best Hyperparameters found:\n",
      "{'C': 1.0, 'class_weight': 'balanced', 'max_iter': 500, 'solver': 'liblinear'}\n",
      "   - Best Cross-Validation Score (F1-weighted): 0.7444\n",
      "Best model parameters: {'C': 1.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 500, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "4. Evaluating model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.83      0.92      0.87       183\n",
      "           O       0.56      0.36      0.44        50\n",
      "           P       0.82      0.80      0.81        59\n",
      "\n",
      "    accuracy                           0.80       292\n",
      "   macro avg       0.74      0.69      0.71       292\n",
      "weighted avg       0.78      0.80      0.78       292\n",
      "\n",
      "True labels distribution: Counter({0: 183, 2: 59, 1: 50})\n",
      "Predicted labels distribution: Counter({0: 203, 2: 57, 1: 32})\n"
     ]
    }
   ],
   "source": [
    "# this is the example of how to use the function\n",
    "# you can change the vectorizer_name and model_name to the ones you want to use\n",
    "# for now we will use word embedding and logistic regression\n",
    "# write the name of your columns in the text_column_name and sentiment_column_name\n",
    "# the text_column_name is the column name of the text data, and sentiment_column_name is\n",
    "\n",
    "# run_pipeline function will return the dataframe with the vectorized text, vectorizer used  and the model\n",
    "# it will also print the results of the model, including the accuracy and F1 score\n",
    "dt= run_pipeline(\n",
    "    vectorizer_name=\"wv\", # BOW, tf, tfidf, wv\n",
    "    model_name=\"logit\", # logit, rf, XGB .#XGB takes long time, can not recommend using it on normal case\n",
    "    df=df_train,\n",
    "    text_column_name=\"processed\",  # this is the column name of the text data, \n",
    "    sentiment_column_name = \"Sentiment\"  # this is the column name of the label data,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_object', 'vectorizer_name', 'vectorizer_object', 'label_encoder', 'y_test', 'y_pred', 'accuracy', 'report'])\n",
      "Vectorizer used:  wv\n",
      "Model used:  LogisticRegression(class_weight='balanced', max_iter=500, random_state=42,\n",
      "                   solver='liblinear')\n",
      "Accuracy:  0.797945205479452\n"
     ]
    }
   ],
   "source": [
    "## the dt is a dictionary that contains the results of the model, including the accuracy and F1 score\n",
    "print(dt.keys())\n",
    "# you can access the results using the keys of the dictionary\n",
    "print(\"Vectorizer used: \", dt[\"vectorizer_name\"])\n",
    "print(\"Model used: \", dt[\"model_object\"])\n",
    "print(\"Accuracy: \", dt[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Dataset for prediction\n",
    "You can use the same format as the training dataset, but ensure that it contains the \"Response\" column for text data. The \"Sentiment\" column is optional for prediction datasets, as it will be generated by the model.\n",
    "Make sure the dataset is saved in the \"New Data\" folder and is in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pl.read_csv(\"New Data/test_142.csv\",encoding='ISO-8859-1') #keep your file here\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_27760\\3171630237.py:6: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  new_data = new_data.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Response</th><th>Sentiment</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;[EMPLOYEE&#x27;S NAME] was great, v…</td><td>&quot;P&quot;</td><td>&quot;great personable helped unders…</td></tr><tr><td>&quot;[EMPLOYEE&#x27;S NAME] was so very …</td><td>&quot;P&quot;</td><td>&quot;helpful called back twice went…</td></tr><tr><td>&quot;[EMPLOYEE&#x27;S NAME] was very hel…</td><td>&quot;P&quot;</td><td>&quot;helpful nice came visit&quot;</td></tr><tr><td>&quot;2 claims were filed because yo…</td><td>&quot;N&quot;</td><td>&quot;2 claim filed employee gave wr…</td></tr><tr><td>&quot;2 of 3 elevators were out of o…</td><td>&quot;N&quot;</td><td>&quot;2 3 elevator order edd 6th flo…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────────────────┬───────────┬─────────────────────────────────┐\n",
       "│ Response                        ┆ Sentiment ┆ processed                       │\n",
       "│ ---                             ┆ ---       ┆ ---                             │\n",
       "│ str                             ┆ str       ┆ str                             │\n",
       "╞═════════════════════════════════╪═══════════╪═════════════════════════════════╡\n",
       "│ [EMPLOYEE'S NAME] was great, v… ┆ P         ┆ great personable helped unders… │\n",
       "│ [EMPLOYEE'S NAME] was so very … ┆ P         ┆ helpful called back twice went… │\n",
       "│ [EMPLOYEE'S NAME] was very hel… ┆ P         ┆ helpful nice came visit         │\n",
       "│ 2 claims were filed because yo… ┆ N         ┆ 2 claim filed employee gave wr… │\n",
       "│ 2 of 3 elevators were out of o… ┆ N         ┆ 2 3 elevator order edd 6th flo… │\n",
       "└─────────────────────────────────┴───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already loaded Word2Vec model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_27760\\3383158272.py:13: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  new_data = new_data.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (25, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Response</th><th>Sentiment</th><th>processed</th><th>predictions</th><th>predictions_label</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;[EMPLOYEE&#x27;S NAME] was great, v…</td><td>&quot;P&quot;</td><td>&quot;great personable helped unders…</td><td>2</td><td>&quot;Positive&quot;</td></tr><tr><td>&quot;[EMPLOYEE&#x27;S NAME] was so very …</td><td>&quot;P&quot;</td><td>&quot;helpful called back twice went…</td><td>2</td><td>&quot;Positive&quot;</td></tr><tr><td>&quot;[EMPLOYEE&#x27;S NAME] was very hel…</td><td>&quot;P&quot;</td><td>&quot;helpful nice came visit&quot;</td><td>2</td><td>&quot;Positive&quot;</td></tr><tr><td>&quot;2 claims were filed because yo…</td><td>&quot;N&quot;</td><td>&quot;2 claim filed employee gave wr…</td><td>0</td><td>&quot;Negative&quot;</td></tr><tr><td>&quot;2 of 3 elevators were out of o…</td><td>&quot;N&quot;</td><td>&quot;2 3 elevator order edd 6th flo…</td><td>0</td><td>&quot;Negative&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Horrible customer service, the…</td><td>&quot;N&quot;</td><td>&quot;horrible customer service whol…</td><td>0</td><td>&quot;Negative&quot;</td></tr><tr><td>&quot;I am to the office I left my p…</td><td>&quot;N&quot;</td><td>&quot;office left phone number suppo…</td><td>0</td><td>&quot;Negative&quot;</td></tr><tr><td>&quot;I am trying to file a claim. I…</td><td>&quot;N&quot;</td><td>&quot;trying file claim trying since…</td><td>0</td><td>&quot;Negative&quot;</td></tr><tr><td>&quot;I came to the office to turn i…</td><td>&quot;N&quot;</td><td>&quot;came office turn document tele…</td><td>0</td><td>&quot;Negative&quot;</td></tr><tr><td>&quot;I emailed several times in the…</td><td>&quot;N&quot;</td><td>&quot;emailed several time portal as…</td><td>0</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (25, 5)\n",
       "┌──────────────────────────┬───────────┬─────────────────────────┬─────────────┬───────────────────┐\n",
       "│ Response                 ┆ Sentiment ┆ processed               ┆ predictions ┆ predictions_label │\n",
       "│ ---                      ┆ ---       ┆ ---                     ┆ ---         ┆ ---               │\n",
       "│ str                      ┆ str       ┆ str                     ┆ i64         ┆ str               │\n",
       "╞══════════════════════════╪═══════════╪═════════════════════════╪═════════════╪═══════════════════╡\n",
       "│ [EMPLOYEE'S NAME] was    ┆ P         ┆ great personable helped ┆ 2           ┆ Positive          │\n",
       "│ great, v…                ┆           ┆ unders…                 ┆             ┆                   │\n",
       "│ [EMPLOYEE'S NAME] was so ┆ P         ┆ helpful called back     ┆ 2           ┆ Positive          │\n",
       "│ very …                   ┆           ┆ twice went…             ┆             ┆                   │\n",
       "│ [EMPLOYEE'S NAME] was    ┆ P         ┆ helpful nice came visit ┆ 2           ┆ Positive          │\n",
       "│ very hel…                ┆           ┆                         ┆             ┆                   │\n",
       "│ 2 claims were filed      ┆ N         ┆ 2 claim filed employee  ┆ 0           ┆ Negative          │\n",
       "│ because yo…              ┆           ┆ gave wr…                ┆             ┆                   │\n",
       "│ 2 of 3 elevators were    ┆ N         ┆ 2 3 elevator order edd  ┆ 0           ┆ Negative          │\n",
       "│ out of o…                ┆           ┆ 6th flo…                ┆             ┆                   │\n",
       "│ …                        ┆ …         ┆ …                       ┆ …           ┆ …                 │\n",
       "│ Horrible customer        ┆ N         ┆ horrible customer       ┆ 0           ┆ Negative          │\n",
       "│ service, the…            ┆           ┆ service whol…           ┆             ┆                   │\n",
       "│ I am to the office I     ┆ N         ┆ office left phone       ┆ 0           ┆ Negative          │\n",
       "│ left my p…               ┆           ┆ number suppo…           ┆             ┆                   │\n",
       "│ I am trying to file a    ┆ N         ┆ trying file claim       ┆ 0           ┆ Negative          │\n",
       "│ claim. I…                ┆           ┆ trying since…           ┆             ┆                   │\n",
       "│ I came to the office to  ┆ N         ┆ came office turn        ┆ 0           ┆ Negative          │\n",
       "│ turn i…                  ┆           ┆ document tele…          ┆             ┆                   │\n",
       "│ I emailed several times  ┆ N         ┆ emailed several time    ┆ 0           ┆ Negative          │\n",
       "│ in the…                  ┆           ┆ portal as…              ┆             ┆                   │\n",
       "└──────────────────────────┴───────────┴─────────────────────────┴─────────────┴───────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT CHANGE THE CODE BELOW\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "vectorizer_func = dt[\"vectorizer_name\"] \n",
    "ml_model=dt[\"model_object\"]\n",
    "\n",
    "new_data = new_data.with_columns(\n",
    "    pl.Series(name=\"predictions\", values=predict_pipeline(new_data, vectorizer_func, ml_model))\n",
    ")\n",
    "\n",
    "# Convert numeric predictions to letter labels\n",
    "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "new_data = new_data.with_columns(\n",
    "    pl.col(\"predictions\").map_elements(lambda x: label_map.get(x, x)).alias(\"predictions_label\")\n",
    ")\n",
    "\n",
    "new_data.head(25)  # Display the first 10 rows of the DataFrame with predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
