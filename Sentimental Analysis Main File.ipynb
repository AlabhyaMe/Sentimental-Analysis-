{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the packages\n",
    "import polars as pl\n",
    "#make sure that this is the main file\n",
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "project_root = os.getcwd()\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 162758 rows and 5 columns\n"
     ]
    }
   ],
   "source": [
    "# keep you training dataset in the training data folder\n",
    "# this template uses csv files \n",
    "# column names can be set in Python but this template does not automatically update the column for the demo \n",
    "# however, the function will give you the option to tell column names for the text and label data\n",
    "\n",
    "df_train = pl.read_csv(\"Training Data/Train.csv\",encoding='ISO-8859-1') \n",
    "print(f\"Dataset shape: {df_train.shape[0]} rows and {df_train.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (162_758, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isFrequentReviewer</th><th>reviewText</th><th>sentiment</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;marvelous_pirate&quot;</td><td>&quot;Benjamin Henry&quot;</td><td>false</td><td>&quot;Henry Selickâs first movie s…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;tony_montana_frodo_baggins_v_r…</td><td>&quot;Felicia Lopez&quot;</td><td>false</td><td>&quot;With a cast that reads like th…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;darth_vader_katniss_everdeen_s…</td><td>&quot;Mr. Charles Burgess&quot;</td><td>true</td><td>&quot;Creed II does not give us anyt…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;lara_croft_glimmer&quot;</td><td>&quot;Ryan Barrett&quot;</td><td>false</td><td>&quot;I know what you&#x27;re thinking, b…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;jason_bourne_surreal_the_termi…</td><td>&quot;Alexander Glover&quot;</td><td>false</td><td>&quot;Director Fernando Meirelles te…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;the_joker_ethereal_captain_jac…</td><td>&quot;Danny Mueller&quot;</td><td>false</td><td>&quot;A top-notch thriller with genu…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;e.t._hannibal_lecter_vito_corl…</td><td>&quot;Jennifer Clayton&quot;</td><td>true</td><td>&quot;Some people find Derek Zooland…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;infinite_enigma_luke_skywalker&quot;</td><td>&quot;Bryan Wilson&quot;</td><td>false</td><td>&quot;This fun, gentle comedy focuse…</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;emerald_oracle_iron_man_wolver…</td><td>&quot;Erik Parker&quot;</td><td>false</td><td>&quot;The film is rescued by a stron…</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;james_t._kirk_phenomenal_zephy…</td><td>&quot;Howard Evans&quot;</td><td>false</td><td>&quot;A peerless exercise in stimulu…</td><td>&quot;POSITIVE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (162_758, 5)\n",
       "┌─────────────────────┬─────────────────────┬────────────────────┬─────────────────────┬───────────┐\n",
       "│ movieid             ┆ reviewerName        ┆ isFrequentReviewer ┆ reviewText          ┆ sentiment │\n",
       "│ ---                 ┆ ---                 ┆ ---                ┆ ---                 ┆ ---       │\n",
       "│ str                 ┆ str                 ┆ bool               ┆ str                 ┆ str       │\n",
       "╞═════════════════════╪═════════════════════╪════════════════════╪═════════════════════╪═══════════╡\n",
       "│ marvelous_pirate    ┆ Benjamin Henry      ┆ false              ┆ Henry Selickâs    ┆ POSITIVE  │\n",
       "│                     ┆                     ┆                    ┆ first movie s…      ┆           │\n",
       "│ tony_montana_frodo_ ┆ Felicia Lopez       ┆ false              ┆ With a cast that    ┆ NEGATIVE  │\n",
       "│ baggins_v_r…        ┆                     ┆                    ┆ reads like th…      ┆           │\n",
       "│ darth_vader_katniss ┆ Mr. Charles Burgess ┆ true               ┆ Creed II does not   ┆ POSITIVE  │\n",
       "│ _everdeen_s…        ┆                     ┆                    ┆ give us anyt…       ┆           │\n",
       "│ lara_croft_glimmer  ┆ Ryan Barrett        ┆ false              ┆ I know what you're  ┆ POSITIVE  │\n",
       "│                     ┆                     ┆                    ┆ thinking, b…        ┆           │\n",
       "│ jason_bourne_surrea ┆ Alexander Glover    ┆ false              ┆ Director Fernando   ┆ POSITIVE  │\n",
       "│ l_the_termi…        ┆                     ┆                    ┆ Meirelles te…       ┆           │\n",
       "│ …                   ┆ …                   ┆ …                  ┆ …                   ┆ …         │\n",
       "│ the_joker_ethereal_ ┆ Danny Mueller       ┆ false              ┆ A top-notch         ┆ POSITIVE  │\n",
       "│ captain_jac…        ┆                     ┆                    ┆ thriller with genu… ┆           │\n",
       "│ e.t._hannibal_lecte ┆ Jennifer Clayton    ┆ true               ┆ Some people find    ┆ NEGATIVE  │\n",
       "│ r_vito_corl…        ┆                     ┆                    ┆ Derek Zooland…      ┆           │\n",
       "│ infinite_enigma_luk ┆ Bryan Wilson        ┆ false              ┆ This fun, gentle    ┆ POSITIVE  │\n",
       "│ e_skywalker         ┆                     ┆                    ┆ comedy focuse…      ┆           │\n",
       "│ emerald_oracle_iron ┆ Erik Parker         ┆ false              ┆ The film is rescued ┆ NEGATIVE  │\n",
       "│ _man_wolver…        ┆                     ┆                    ┆ by a stron…         ┆           │\n",
       "│ james_t._kirk_pheno ┆ Howard Evans        ┆ false              ┆ A peerless exercise ┆ POSITIVE  │\n",
       "│ menal_zephy…        ┆                     ┆                    ┆ in stimulu…         ┆           │\n",
       "└─────────────────────┴─────────────────────┴────────────────────┴─────────────────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "df_train.fill_null(\"\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data 'punkt' already present.\n",
      "NLTK data 'stopwords' already present.\n",
      "Downloading NLTK data: wordnet...\n",
      "NLTK data 'wordnet' downloaded.\n",
      "Downloading NLTK data: omw-1.4...\n",
      "NLTK data 'omw-1.4' downloaded.\n",
      "NLTK data 'wordnet' downloaded.\n",
      "Downloading NLTK data: omw-1.4...\n",
      "NLTK data 'omw-1.4' downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\meala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\meala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# here I have three python script I built to pre_process the data and running the pipeline\n",
    "# you can find the code in the tools/preprocess.py file\n",
    "# you can find  the code in the tools/pipeline.py file\n",
    "# the pre_process function is used to clean the text data, there are various options available, please check the tools/preprocess.py file for details\n",
    "# the run_pipeline function is used to run the sentimental analysis pipeline, it takes the training data and the vectorizer and machine learning methods as input, and returns the results\n",
    "import importlib\n",
    "from tools.preprocess import pre_process\n",
    "#this function will run the sentimental analysis in the training data and return the results\n",
    "from tools.pipeline import run_pipeline\n",
    "# this function will run the sentimental analysis in the new data and return the predictions\n",
    "from tools.predict import predict_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Henry Selickâ\\x80\\x99s first movie since 2009â\\x80\\x99s Coraline. His fifth stop-motion masterpiece.',\n",
       " 'henry selickas first movie since 2009as coraline fifth stopmotion masterpiece',\n",
       " 'henry selickas first movie since 2009as coraline fifth stopmotion masterpiece')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use the pre_process function to clean the text data\n",
    "response_column = \"reviewText\" # feel free to change the column name to your text column name\n",
    "sentiment_column = \"sentiment\" # feel free to change the column name to your label column name\n",
    "df_train[response_column][0] , pre_process(df_train[response_column][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_22108\\2369074634.py:3: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_train = df_train.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isFrequentReviewer</th><th>reviewText</th><th>sentiment</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;marvelous_pirate&quot;</td><td>&quot;Benjamin Henry&quot;</td><td>false</td><td>&quot;Henry Selickâs first movie s…</td><td>&quot;POSITIVE&quot;</td><td>&quot;henry selickas first movie sin…</td></tr><tr><td>&quot;tony_montana_frodo_baggins_v_r…</td><td>&quot;Felicia Lopez&quot;</td><td>false</td><td>&quot;With a cast that reads like th…</td><td>&quot;NEGATIVE&quot;</td><td>&quot;cast read like vogue oscar par…</td></tr><tr><td>&quot;darth_vader_katniss_everdeen_s…</td><td>&quot;Mr. Charles Burgess&quot;</td><td>true</td><td>&quot;Creed II does not give us anyt…</td><td>&quot;POSITIVE&quot;</td><td>&quot;creed ii give u anything anoth…</td></tr><tr><td>&quot;lara_croft_glimmer&quot;</td><td>&quot;Ryan Barrett&quot;</td><td>false</td><td>&quot;I know what you&#x27;re thinking, b…</td><td>&quot;POSITIVE&quot;</td><td>&quot;know thinking limitless bradle…</td></tr><tr><td>&quot;jason_bourne_surreal_the_termi…</td><td>&quot;Alexander Glover&quot;</td><td>false</td><td>&quot;Director Fernando Meirelles te…</td><td>&quot;POSITIVE&quot;</td><td>&quot;director fernando meirelles te…</td></tr><tr><td>&quot;enigma_mystique_secret&quot;</td><td>&quot;Morgan Hurst&quot;</td><td>true</td><td>&quot;&quot;Kajillionaire&quot; is a rich piec…</td><td>&quot;POSITIVE&quot;</td><td>&quot;kajillionaire rich piece story…</td></tr><tr><td>&quot;indiana_jones_sherlock_holmes_…</td><td>&quot;Kari Wolf&quot;</td><td>false</td><td>&quot;A heartfelt story with a lovel…</td><td>&quot;POSITIVE&quot;</td><td>&quot;heartfelt story lovely perform…</td></tr><tr><td>&quot;john_mcclane_james_t._kirk_ben…</td><td>&quot;Johnny Caldwell&quot;</td><td>false</td><td>&quot;If a bit long for a cartoon fe…</td><td>&quot;POSITIVE&quot;</td><td>&quot;bit long cartoon feature proba…</td></tr><tr><td>&quot;starlight_travis_bickle_tyler_…</td><td>&quot;Michael Chavez&quot;</td><td>true</td><td>&quot;Anchored by a charming perform…</td><td>&quot;POSITIVE&quot;</td><td>&quot;anchored charming performance …</td></tr><tr><td>&quot;frodo_baggins_quest_darth_vade…</td><td>&quot;Catherine Clements&quot;</td><td>false</td><td>&quot;It&#x27;s largely a Hanks solo show…</td><td>&quot;POSITIVE&quot;</td><td>&quot;largely hank solo show beloved…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌─────────────────┬─────────────────┬────────────────┬────────────────┬───────────┬────────────────┐\n",
       "│ movieid         ┆ reviewerName    ┆ isFrequentRevi ┆ reviewText     ┆ sentiment ┆ processed      │\n",
       "│ ---             ┆ ---             ┆ ewer           ┆ ---            ┆ ---       ┆ ---            │\n",
       "│ str             ┆ str             ┆ ---            ┆ str            ┆ str       ┆ str            │\n",
       "│                 ┆                 ┆ bool           ┆                ┆           ┆                │\n",
       "╞═════════════════╪═════════════════╪════════════════╪════════════════╪═══════════╪════════════════╡\n",
       "│ marvelous_pirat ┆ Benjamin Henry  ┆ false          ┆ Henry          ┆ POSITIVE  ┆ henry selickas │\n",
       "│ e               ┆                 ┆                ┆ Selickâs     ┆           ┆ first movie    │\n",
       "│                 ┆                 ┆                ┆ first movie s… ┆           ┆ sin…           │\n",
       "│ tony_montana_fr ┆ Felicia Lopez   ┆ false          ┆ With a cast    ┆ NEGATIVE  ┆ cast read like │\n",
       "│ odo_baggins_v_r ┆                 ┆                ┆ that reads     ┆           ┆ vogue oscar    │\n",
       "│ …               ┆                 ┆                ┆ like th…       ┆           ┆ par…           │\n",
       "│ darth_vader_kat ┆ Mr. Charles     ┆ true           ┆ Creed II does  ┆ POSITIVE  ┆ creed ii give  │\n",
       "│ niss_everdeen_s ┆ Burgess         ┆                ┆ not give us    ┆           ┆ u anything     │\n",
       "│ …               ┆                 ┆                ┆ anyt…          ┆           ┆ anoth…         │\n",
       "│ lara_croft_glim ┆ Ryan Barrett    ┆ false          ┆ I know what    ┆ POSITIVE  ┆ know thinking  │\n",
       "│ mer             ┆                 ┆                ┆ you're         ┆           ┆ limitless      │\n",
       "│                 ┆                 ┆                ┆ thinking, b…   ┆           ┆ bradle…        │\n",
       "│ jason_bourne_su ┆ Alexander       ┆ false          ┆ Director       ┆ POSITIVE  ┆ director       │\n",
       "│ rreal_the_termi ┆ Glover          ┆                ┆ Fernando       ┆           ┆ fernando       │\n",
       "│ …               ┆                 ┆                ┆ Meirelles te…  ┆           ┆ meirelles te…  │\n",
       "│ enigma_mystique ┆ Morgan Hurst    ┆ true           ┆ \"Kajillionaire ┆ POSITIVE  ┆ kajillionaire  │\n",
       "│ _secret         ┆                 ┆                ┆ \" is a rich    ┆           ┆ rich piece     │\n",
       "│                 ┆                 ┆                ┆ piec…          ┆           ┆ story…         │\n",
       "│ indiana_jones_s ┆ Kari Wolf       ┆ false          ┆ A heartfelt    ┆ POSITIVE  ┆ heartfelt      │\n",
       "│ herlock_holmes_ ┆                 ┆                ┆ story with a   ┆           ┆ story lovely   │\n",
       "│ …               ┆                 ┆                ┆ lovel…         ┆           ┆ perform…       │\n",
       "│ john_mcclane_ja ┆ Johnny Caldwell ┆ false          ┆ If a bit long  ┆ POSITIVE  ┆ bit long       │\n",
       "│ mes_t._kirk_ben ┆                 ┆                ┆ for a cartoon  ┆           ┆ cartoon        │\n",
       "│ …               ┆                 ┆                ┆ fe…            ┆           ┆ feature proba… │\n",
       "│ starlight_travi ┆ Michael Chavez  ┆ true           ┆ Anchored by a  ┆ POSITIVE  ┆ anchored       │\n",
       "│ s_bickle_tyler_ ┆                 ┆                ┆ charming       ┆           ┆ charming       │\n",
       "│ …               ┆                 ┆                ┆ perform…       ┆           ┆ performance …  │\n",
       "│ frodo_baggins_q ┆ Catherine       ┆ false          ┆ It's largely a ┆ POSITIVE  ┆ largely hank   │\n",
       "│ uest_darth_vade ┆ Clements        ┆                ┆ Hanks solo     ┆           ┆ solo show      │\n",
       "│ …               ┆                 ┆                ┆ show…          ┆           ┆ beloved…       │\n",
       "└─────────────────┴─────────────────┴────────────────┴────────────────┴───────────┴────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make changes as necessary\n",
    "# inside the map_elements, add  the parameters [pre_process(x, parameters_to_be_added)] and set it True/False if it differs from the defualt value\n",
    "df_train = df_train.with_columns(\n",
    "    pl.col(response_column).map_elements(lambda x: pre_process(x, remove_brackets=True)).alias(\"processed\")  #add inside the map_elements\n",
    ")\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are four text representation / vectorizer methods available \n",
    "#### #in the function run_pipeline, we shall make use of this, write the words inside [ ] for the methods you want to use\n",
    "#### 1. Bag of Words [BOW] \n",
    "#### 2. Term Frequency [tf]\n",
    "#### 3. TF -IDF    [tfidf]\n",
    "#### 4. Word Embedding using Word2Vec (you can use other packages with slight changes) [wv] \n",
    "         # Word Embedding uses defualt 300 values; this will take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### in this template, there are also three machine learning methods that can be used\n",
    "#### 1. Logistic Regression [logit]\n",
    "#### 2. Random forest (recommended) (rf)\n",
    "#### 3. XGBoosting  [XGB](word embedding and XGBoost may take long time to complete, combination of both is not recommended in local machine)\n",
    "\n",
    "#I will keep this repository updated, and I will add more methods in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Pipeline for Wv + Logit ---\n",
      "WARNING: Dropped 6447 rows due to missing values (None) in 'processed' or 'sentiment' columns. Original rows: 162758, Rows after dropping: 156311\n",
      "Labels encoded: Original -> ['NEGATIVE' 'POSITIVE'], Encoded -> [0 1]\n",
      "1. Vectorizing entire dataset (X)...\n",
      "Loading pre-trained word2vec-google-news-300 model (this may take a few minutes)...\n",
      "Word2Vec model loaded.\n",
      "2. Splitting data into train/test...\n",
      "3. Training and predicting...\n",
      "   - Starting Logistic Regression training with GridSearchCV for hyperparameter tuning...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "   - Best Hyperparameters found:\n",
      "{'C': 10.0, 'class_weight': None, 'max_iter': 500, 'solver': 'liblinear'}\n",
      "   - Best Cross-Validation Score (F1-weighted): 0.7592\n",
      "Best model parameters: {'C': 10.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 500, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "4. Evaluating model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.71      0.53      0.61     10319\n",
      "    POSITIVE       0.79      0.89      0.84     20944\n",
      "\n",
      "    accuracy                           0.77     31263\n",
      "   macro avg       0.75      0.71      0.72     31263\n",
      "weighted avg       0.77      0.77      0.76     31263\n",
      "\n",
      "True labels distribution: Counter({1: 20944, 0: 10319})\n",
      "Predicted labels distribution: Counter({1: 23539, 0: 7724})\n"
     ]
    }
   ],
   "source": [
    "# this is the example of how to use the function\n",
    "# you can change the vectorizer_name and model_name to the ones you want to use\n",
    "# for now we will use word embedding and logistic regression\n",
    "# write the name of your columns in the text_column_name and sentiment_column_name\n",
    "# the text_column_name is the column name of the text data, and sentiment_column_name is\n",
    "\n",
    "# run_pipeline function will return the dataframe with the vectorized text, vectorizer used  and the model\n",
    "# it will also print the results of the model, including the accuracy and F1 score\n",
    "dt= run_pipeline(\n",
    "    vectorizer_name=\"wv\", # BOW, tf, tfidf, wv\n",
    "    model_name=\"logit\", # logit, rf, XGB .#XGB takes long time, can not recommend using it on normal case\n",
    "    df=df_train,\n",
    "    text_column_name=\"processed\",  # this is the column name of the text data, \n",
    "    sentiment_column_name = \"sentiment\"  # this is the column name of the label data,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_object', 'vectorizer_name', 'vectorizer_object', 'label_encoder', 'y_test', 'y_pred', 'accuracy', 'report'])\n",
      "Vectorizer used:  wv\n",
      "Model used:  LogisticRegression(C=10.0, max_iter=500, random_state=42, solver='liblinear')\n",
      "Accuracy:  0.7724146754949941\n"
     ]
    }
   ],
   "source": [
    "## the dt is a dictionary that contains the results of the model, including the accuracy and F1 score\n",
    "print(dt.keys())\n",
    "# you can access the results using the keys of the dictionary\n",
    "print(\"Vectorizer used: \", dt[\"vectorizer_name\"])\n",
    "print(\"Model used: \", dt[\"model_object\"])\n",
    "print(\"Accuracy: \", dt[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Dataset for prediction\n",
    "You can use the same format as the training dataset, but ensure that it contains the \"Response\" column for text data. The \"Sentiment\" column is optional for prediction datasets, as it will be generated by the model.\n",
    "Make sure the dataset is saved in the \"New Data\" folder and is in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isTopCritic</th><th>reviewText</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;legend_marty_mcfly_oracle&quot;</td><td>&quot;John Kim&quot;</td><td>false</td><td>&quot;Green slowly cranks up the dre…</td></tr><tr><td>&quot;terminator_katniss_everdeen_gl…</td><td>&quot;Brian Chaney&quot;</td><td>false</td><td>&quot;Philip Noyce&#x27;s direction is el…</td></tr><tr><td>&quot;james_bond_labyrinth_gollum&quot;</td><td>&quot;Danielle Parker&quot;</td><td>false</td><td>&quot;It wouldn&#x27;t do to say what pat…</td></tr><tr><td>&quot;v_quest_han_solo_wondrous&quot;</td><td>&quot;Brittany Lane&quot;</td><td>false</td><td>&quot;Pig is not exactly the arthous…</td></tr><tr><td>&quot;enigma_hulk_surreal_starlight&quot;</td><td>&quot;Justin Willis&quot;</td><td>false</td><td>&quot;An imaginative no-budget music…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────────────────┬─────────────────┬─────────────┬─────────────────────────────┐\n",
       "│ movieid                         ┆ reviewerName    ┆ isTopCritic ┆ reviewText                  │\n",
       "│ ---                             ┆ ---             ┆ ---         ┆ ---                         │\n",
       "│ str                             ┆ str             ┆ bool        ┆ str                         │\n",
       "╞═════════════════════════════════╪═════════════════╪═════════════╪═════════════════════════════╡\n",
       "│ legend_marty_mcfly_oracle       ┆ John Kim        ┆ false       ┆ Green slowly cranks up the  │\n",
       "│                                 ┆                 ┆             ┆ dre…                        │\n",
       "│ terminator_katniss_everdeen_gl… ┆ Brian Chaney    ┆ false       ┆ Philip Noyce's direction is │\n",
       "│                                 ┆                 ┆             ┆ el…                         │\n",
       "│ james_bond_labyrinth_gollum     ┆ Danielle Parker ┆ false       ┆ It wouldn't do to say what  │\n",
       "│                                 ┆                 ┆             ┆ pat…                        │\n",
       "│ v_quest_han_solo_wondrous       ┆ Brittany Lane   ┆ false       ┆ Pig is not exactly the      │\n",
       "│                                 ┆                 ┆             ┆ arthous…                    │\n",
       "│ enigma_hulk_surreal_starlight   ┆ Justin Willis   ┆ false       ┆ An imaginative no-budget    │\n",
       "│                                 ┆                 ┆             ┆ music…                      │\n",
       "└─────────────────────────────────┴─────────────────┴─────────────┴─────────────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pl.read_csv(\"New Data/test.csv\",encoding='ISO-8859-1') #keep your file here\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_22108\\2428930420.py:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  new_data = new_data.with_columns(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movieid</th><th>reviewerName</th><th>isTopCritic</th><th>reviewText</th><th>processed</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;legend_marty_mcfly_oracle&quot;</td><td>&quot;John Kim&quot;</td><td>false</td><td>&quot;Green slowly cranks up the dre…</td><td>&quot;green slowly crank dread style…</td></tr><tr><td>&quot;terminator_katniss_everdeen_gl…</td><td>&quot;Brian Chaney&quot;</td><td>false</td><td>&quot;Philip Noyce&#x27;s direction is el…</td><td>&quot;philip noyce direction elegant…</td></tr><tr><td>&quot;james_bond_labyrinth_gollum&quot;</td><td>&quot;Danielle Parker&quot;</td><td>false</td><td>&quot;It wouldn&#x27;t do to say what pat…</td><td>&quot;would nt say path maria ultima…</td></tr><tr><td>&quot;v_quest_han_solo_wondrous&quot;</td><td>&quot;Brittany Lane&quot;</td><td>false</td><td>&quot;Pig is not exactly the arthous…</td><td>&quot;pig exactly arthouse john wick…</td></tr><tr><td>&quot;enigma_hulk_surreal_starlight&quot;</td><td>&quot;Justin Willis&quot;</td><td>false</td><td>&quot;An imaginative no-budget music…</td><td>&quot;imaginative nobudget musical s…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────┬─────────────────┬─────────────┬─────────────────────┬─────────────────────┐\n",
       "│ movieid              ┆ reviewerName    ┆ isTopCritic ┆ reviewText          ┆ processed           │\n",
       "│ ---                  ┆ ---             ┆ ---         ┆ ---                 ┆ ---                 │\n",
       "│ str                  ┆ str             ┆ bool        ┆ str                 ┆ str                 │\n",
       "╞══════════════════════╪═════════════════╪═════════════╪═════════════════════╪═════════════════════╡\n",
       "│ legend_marty_mcfly_o ┆ John Kim        ┆ false       ┆ Green slowly cranks ┆ green slowly crank  │\n",
       "│ racle                ┆                 ┆             ┆ up the dre…         ┆ dread style…        │\n",
       "│ terminator_katniss_e ┆ Brian Chaney    ┆ false       ┆ Philip Noyce's      ┆ philip noyce        │\n",
       "│ verdeen_gl…          ┆                 ┆             ┆ direction is el…    ┆ direction elegant…  │\n",
       "│ james_bond_labyrinth ┆ Danielle Parker ┆ false       ┆ It wouldn't do to   ┆ would nt say path   │\n",
       "│ _gollum              ┆                 ┆             ┆ say what pat…       ┆ maria ultima…       │\n",
       "│ v_quest_han_solo_won ┆ Brittany Lane   ┆ false       ┆ Pig is not exactly  ┆ pig exactly         │\n",
       "│ drous                ┆                 ┆             ┆ the arthous…        ┆ arthouse john wick… │\n",
       "│ enigma_hulk_surreal_ ┆ Justin Willis   ┆ false       ┆ An imaginative      ┆ imaginative         │\n",
       "│ starlight            ┆                 ┆             ┆ no-budget music…    ┆ nobudget musical s… │\n",
       "└──────────────────────┴─────────────────┴─────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data.with_columns(\n",
    "    pl.col(\"reviewText\").map_elements(pre_process).alias(\"processed\")  #add inside the map_elements\n",
    ")\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already loaded Word2Vec model.\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\meala\\AppData\\Local\\Temp\\ipykernel_22108\\1753209415.py\", line 8, in <module>\n",
      "    pl.Series(name=\"predictions\", values=predict_pipeline(\n",
      "                                         ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\Dropbox\\Data Work\\Text NLP\\tools\\predict.py\", line 32, in predict_pipeline\n",
      "  File \"c:\\Users\\meala\\Dropbox\\Data Work\\Text NLP\\Vect\\wv.py\", line 33, in vectorize\n",
      "    tokenized = [sentence.split() for sentence in texts]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\Dropbox\\Data Work\\Text NLP\\Vect\\wv.py\", line 33, in <listcomp>\n",
      "    tokenized = [sentence.split() for sentence in texts]\n",
      "                 ^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\meala\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THE CODE BELOW\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "vectorizer_func = dt[\"vectorizer_name\"] \n",
    "ml_model=dt[\"model_object\"]\n",
    "\n",
    "new_data = new_data.with_columns(\n",
    "    pl.Series(name=\"predictions\", values=predict_pipeline(\n",
    "        df = new_data,\n",
    "        text_column_name = \"processed\",  # this is the column name of the text data in the new data\n",
    "        vectorizer_func = vectorizer_func,  # this is the vectorizer function used in the training data\n",
    "        ml_model = ml_model))\n",
    ")\n",
    "\n",
    "# Convert numeric predictions to letter labels\n",
    "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "new_data = new_data.with_columns(\n",
    "    pl.col(\"predictions\").map_elements(lambda x: label_map.get(x, x)).alias(\"predictions_label\")\n",
    ")\n",
    "\n",
    "new_data.head(25)  # Display the first 10 rows of the DataFrame with predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
